# MI-Attack: More Independent, Meaningfully Realistic

I modified the adversary 1 of the paper titled ML-Leaks: Model and Data Independent
Membership Inference Attacks and Defenses on
Machine Learning Models by Salem et al. in this experiment  and proposed that the membership inference attack can be accomplished by retaining only reasonably close accuracy of the shadow model as the target model. It is not necessary that 
the shadow model has to has the same ML algorithm and hyperparameters as the target model.

As part of my final project for the Machine Learning in Cybersecurity course from Prof. Dr. Mario Fritz from Saarland University, I designed this experiment to relax a few assumption considered in the paper. Unfortunately, the results are not significant enough to draw a correct conclusion. Performing the experiment with different data sets can lead to interesting results.

Feel free to look into my code and contribute to improve the overall experiment results.
