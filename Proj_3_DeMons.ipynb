{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proj_3_DeMons.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd061b00720c4849bf17213e38990511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63b2488dbf3842ab91b216d3cfb90f26",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_967510754b014e468855500e06107f19",
              "IPY_MODEL_d29c064db08b469bafee0934829f079a"
            ]
          }
        },
        "63b2488dbf3842ab91b216d3cfb90f26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "967510754b014e468855500e06107f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db412090d67c4fe7a6bca511104ed5fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9322ccff61a046caa488d30f6bff9cf5"
          }
        },
        "d29c064db08b469bafee0934829f079a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c3f82ab6202a449aad84e5528cc8e915",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169009152/? [00:20&lt;00:00, 33502923.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60ac83b5d6fa4f76a42bf3016d0e409d"
          }
        },
        "db412090d67c4fe7a6bca511104ed5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9322ccff61a046caa488d30f6bff9cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3f82ab6202a449aad84e5528cc8e915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60ac83b5d6fa4f76a42bf3016d0e409d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0jLonLA90co"
      },
      "source": [
        "<h1><b>Machine Learning in CyberSecurity</b></h1>\r\n",
        "<h2>by <b>Prof. Dr. Mario Frtiz</b></h2>\r\n",
        "<h2><b>Winter 2020/21</b></h2>\r\n",
        "<br/>\r\n",
        "<h3><b>Final Project:</b> MI Attack: More Independent, Meaningfully Realitic</h3>\r\n",
        "\r\n",
        "<h3><b>Team:</b> <span style=\"color:red;\">DeMons</span></h3>\r\n",
        "<br/>\r\n",
        "<h3><b>Members:</b></h3> \r\n",
        "<p><b>Name:</b> Rayhanul Islam Rumel <br/>\r\n",
        "<b>Email:</b> s8rarume@stud.uni-saarland.de <br/>\r\n",
        "<b>Matriculation Number:</b> 2576541</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1KNNiL3Pgco"
      },
      "source": [
        "#Import Libraries\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import numpy as np\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, models, transforms\r\n",
        "from torch.utils.data import Subset\r\n",
        "from torch.utils.data import Subset, Dataset, DataLoader\r\n",
        "from torchvision.datasets import CIFAR100\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "import time\r\n",
        "import os\r\n",
        "import copy\r\n",
        "import pandas as pd\r\n",
        "import random\r\n",
        "\r\n",
        "plt.ion()   # interactive mode\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heQcjr7nG2XD"
      },
      "source": [
        "def get_target_label_idx(labels, targets, shots=5, test=False):\r\n",
        "    \"\"\"\r\n",
        "    Get the indices of labels that are included in targets.\r\n",
        "    :param labels: array of labels\r\n",
        "    :param targets: list/tuple of target labels\r\n",
        "    :return: list with indices of target labels\r\n",
        "    \"\"\"\r\n",
        "    final_list = []\r\n",
        "    \r\n",
        "    for t in targets:\r\n",
        "        if test:\r\n",
        "            final_list += np.argwhere(np.isin(labels, t)).flatten().tolist()\r\n",
        "        else:\r\n",
        "            final_list += np.argwhere(np.isin(labels, t)).flatten().tolist()\r\n",
        "    \r\n",
        "    return final_list"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3MwALbwNysf"
      },
      "source": [
        "class MyCIFAR100(torchvision.datasets.CIFAR100):\r\n",
        "    \"\"\"Torchvision CIFAR100 class with patch of __getitem__ method to also return the index of a data sample.\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, *args, **kwargs):\r\n",
        "        super(MyCIFAR100, self).__init__(*args, **kwargs)\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        \"\"\"Override the original method of the CIFAR100 class.\r\n",
        "        Args:\r\n",
        "            index (int): Index\r\n",
        "        Returns:\r\n",
        "            triple: (image, target, index) where target is index of the target class.\r\n",
        "        \"\"\"\r\n",
        "        if self.train:\r\n",
        "            img, target = self.data[index], self.targets[index]\r\n",
        "        else:\r\n",
        "            img, target = self.test_data[index], self.targets[index]\r\n",
        "\r\n",
        "        # doing this so that it is consistent with all other datasets\r\n",
        "        # to return a PIL Image\r\n",
        "        # print(type(img))\r\n",
        "        img = Image.fromarray(img)\r\n",
        "\r\n",
        "\r\n",
        "        if self.transform is not None:\r\n",
        "            img = self.transform(img)\r\n",
        "\r\n",
        "        if self.target_transform is not None:\r\n",
        "            target = self.target_transform(target)\r\n",
        "\r\n",
        "        return img, target, index  # only line changed"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "dd061b00720c4849bf17213e38990511",
            "63b2488dbf3842ab91b216d3cfb90f26",
            "967510754b014e468855500e06107f19",
            "d29c064db08b469bafee0934829f079a",
            "db412090d67c4fe7a6bca511104ed5fb",
            "9322ccff61a046caa488d30f6bff9cf5",
            "c3f82ab6202a449aad84e5528cc8e915",
            "60ac83b5d6fa4f76a42bf3016d0e409d"
          ]
        },
        "id": "qGgK6PIEBNG6",
        "outputId": "01896778-afd5-456a-9fb1-be9cded3622b"
      },
      "source": [
        "#Data Process\r\n",
        "\r\n",
        "target_transform = transforms.Lambda(lambda x: convert_label(x))\r\n",
        "transform = transforms.Compose([transforms.ToTensor(),\r\n",
        "                                transforms.Normalize(mean=[n/255.\r\n",
        "                                for n in [129.3, 124.1, 112.4]], std=[n/255. for n in [68.2,  65.4,  70.4]])])\r\n",
        "        \r\n",
        "train_set = MyCIFAR100(root='data/', train=True, download=True,\r\n",
        "                            transform=transform) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd061b00720c4849bf17213e38990511",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGKRUbI5HBTh"
      },
      "source": [
        "normal_class=[0,1,2,3,4,5,6,7,8,9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99]\r\n",
        "normal_classes = tuple(normal_class)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZToTey7XEdD-"
      },
      "source": [
        "train_index = get_target_label_idx(train_set.targets, normal_classes, shots=5)\r\n",
        "random.shuffle(train_index) #shuffling before split\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSNhGNIDKXKs",
        "outputId": "4d3adb31-acf9-492d-d5be-7a505bfc7ef6"
      },
      "source": [
        "# splitting to target and shadowset\r\n",
        "train_index_half_len = int(len(train_index)/2)\r\n",
        "shadow_set = Subset(train_set, train_index[0:train_index_half_len])\r\n",
        "target_set = Subset(train_set, train_index[train_index_half_len:])\r\n",
        "\r\n",
        "shadow_half_len = int(len(shadow_set)/2)\r\n",
        "print(\"shadow half len: \", shadow_half_len)\r\n",
        "shadow_train = Subset(shadow_set, list(range(0, shadow_half_len)))\r\n",
        "shadow_test = Subset (shadow_set, list(range(shadow_half_len, len(shadow_set))))\r\n",
        "\r\n",
        "\r\n",
        "target_half_len = int(len(target_set)/2)\r\n",
        "print(\"Target half len: \", target_half_len)\r\n",
        "target_train = Subset(target_set, list(range(0, target_half_len)))\r\n",
        "target_unknown = Subset(target_set, list(range(target_half_len, len(target_set))))\r\n",
        "\r\n",
        "classes = ('beaver', 'dolphin', 'otter', 'seal', 'whale', 'aquarium fish', 'flatfish', 'ray', 'shark', 'trout',  'orchids', 'poppies', 'roses', 'sunflowers', 'tulips',  'bottles', 'bowls', 'cans', 'cups', 'plates', \r\n",
        "'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers',  'clock', 'computer keyboard', 'lamp', 'telephone', 'television',  'bed', 'chair', 'couch', 'table', 'wardrobe',  'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach', \r\n",
        "'bear', 'leopard', 'lion', 'tiger', 'wolf',  'bridge', 'castle', 'house', 'road', 'skyscraper',  'cloud', 'forest', 'mountain', 'plain', 'sea',  'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo', \r\n",
        "'fox', 'porcupine', 'possum', 'raccoon', 'skunk',  'crab', 'lobster', 'snail', 'spider', 'worm',  'baby', 'boy', 'girl', 'man', 'woman',  'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle', \r\n",
        "'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel',  'maple', 'oak', 'palm', 'pine', 'willow',  'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train',  'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shadow half len:  12500\n",
            "Target half len:  12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5cYVjXgLoXz"
      },
      "source": [
        "shadow_train_loader = DataLoader(shadow_train, batch_size=64, shuffle=True, num_workers=0)\r\n",
        "shadow_test_loader = DataLoader(shadow_test, batch_size=64, shuffle=True, num_workers=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHOIHW997AYy"
      },
      "source": [
        "\"\"\" Shadow Model \"\"\"\r\n",
        "\r\n",
        "class Shadow_LeNet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Shadow_LeNet, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3,6,5)\r\n",
        "        self.pool = nn.MaxPool2d(2,2)\r\n",
        "        self.conv2 = nn.Conv2d(6,16,5)\r\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)\r\n",
        "        self.fc2 = nn.Linear(120,84)\r\n",
        "        self.fc3 = nn.Linear(84,100)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.pool(F.relu(self.conv1(x)))\r\n",
        "        out = self.pool(F.relu(self.conv2(out)))\r\n",
        "        out = out.view(out.size(0),-1)\r\n",
        "        out = F.relu(self.fc1(out))\r\n",
        "        out = F.relu(self.fc2(out))\r\n",
        "        out = self.fc3(out)\r\n",
        "        return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xvtr0wEdmBR"
      },
      "source": [
        "\"\"\" Base Shadow Model \"\"\"\r\n",
        "\r\n",
        "class Base_Shadow_LeNet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Base_Shadow_LeNet, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\r\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\r\n",
        "        self.fc2   = nn.Linear(120, 84)\r\n",
        "        self.fc3   = nn.Linear(84, 100)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = F.relu(self.conv1(x))\r\n",
        "        out = F.max_pool2d(out, 2)\r\n",
        "        out = F.relu(self.conv2(out))\r\n",
        "        out = F.max_pool2d(out, 2)\r\n",
        "        out = out.view(out.size(0), -1)\r\n",
        "        out = F.relu(self.fc1(out))\r\n",
        "        out = F.relu(self.fc2(out))\r\n",
        "        out = self.fc3(out)\r\n",
        "        return out"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve6di2vy7Zmp",
        "outputId": "815c9d7b-fadb-4984-8a90-f98915639655"
      },
      "source": [
        "Resnet_Shadow = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to /root/.cache/torch/hub/v0.6.0.zip\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5_L8P5X-M-c"
      },
      "source": [
        "\"\"\" Target Model \"\"\"\r\n",
        "\r\n",
        "class Target_LeNet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Target_LeNet, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\r\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\r\n",
        "        self.fc2   = nn.Linear(120, 84)\r\n",
        "        self.fc3   = nn.Linear(84, 100)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = F.relu(self.conv1(x))\r\n",
        "        out = F.max_pool2d(out, 2)\r\n",
        "        out = F.relu(self.conv2(out))\r\n",
        "        out = F.max_pool2d(out, 2)\r\n",
        "        out = out.view(out.size(0), -1)\r\n",
        "        out = F.relu(self.fc1(out))\r\n",
        "        out = F.relu(self.fc2(out))\r\n",
        "        out = self.fc3(out)\r\n",
        "        return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fyifqbUTD-J"
      },
      "source": [
        "\"\"\" Attack Model Implementation \"\"\"\r\n",
        "\r\n",
        "class AttackModel(nn.Module):\r\n",
        "  def __init__(self, input_size, hidden_size):\r\n",
        "      super(AttackModel, self).__init__()\r\n",
        "      self.input_size = input_size\r\n",
        "      self.hidden_size  = hidden_size\r\n",
        "\r\n",
        "      self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\r\n",
        "      self.fc2 = torch.nn.Linear(self.hidden_size, 2)\r\n",
        "      # self.sigmoid = torch.nn.Softmax()\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "      x = self.fc1(x)\r\n",
        "      x = F.softmax(self.fc2(x))\r\n",
        "      output = x\r\n",
        "      \r\n",
        "      return output"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3zj4xflbalU"
      },
      "source": [
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=20, attack=False):\r\n",
        "    since = time.time()\r\n",
        "\r\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "    best_acc = 0.0\r\n",
        "\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\r\n",
        "        print('-' * 10)\r\n",
        "\r\n",
        "        # Each epoch has a training and validation phase\r\n",
        "        for phase in ['train', 'val']:\r\n",
        "            \r\n",
        "            if phase == 'train':\r\n",
        "                model.train()  # Set model to training mode\r\n",
        "                \r\n",
        "                running_loss = 0.0\r\n",
        "                running_corrects = 0\r\n",
        "                \r\n",
        "                for data in train_loader:\r\n",
        "                    if attack:\r\n",
        "                      inputs, labels = data\r\n",
        "                    else:\r\n",
        "                      inputs, labels, idx = data\r\n",
        "\r\n",
        "                    inputs = inputs.to(device)\r\n",
        "                    labels = labels.to(device)\r\n",
        "                    \r\n",
        "                    \r\n",
        "                    optimizer.zero_grad()\r\n",
        "                    with torch.set_grad_enabled(True):\r\n",
        "                        outputs = model(inputs)\r\n",
        "                        \r\n",
        "                        _, preds = torch.max(outputs, 1)\r\n",
        "                        # print(preds, labels)\r\n",
        "                        loss = criterion(outputs, labels)\r\n",
        "                        \r\n",
        "                        loss.backward()\r\n",
        "                        optimizer.step()\r\n",
        "                    \r\n",
        "                    running_loss += loss.item() * inputs.size(0)\r\n",
        "                    running_corrects += torch.sum(preds == labels.data)\r\n",
        "                    \r\n",
        "                    \r\n",
        "                scheduler.step()\r\n",
        "                print(running_corrects)\r\n",
        "                epoch_loss = running_loss / train_size\r\n",
        "                epoch_acc = running_corrects.double() / train_size\r\n",
        "\r\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format('Train', epoch_loss, epoch_acc))\r\n",
        "                    \r\n",
        "            else:\r\n",
        "                \r\n",
        "                model.eval()   # Set model to evaluate mode\r\n",
        "                \r\n",
        "                running_loss = 0.0\r\n",
        "                running_corrects = 0\r\n",
        "                \r\n",
        "                for data in test_loader:\r\n",
        "                    if attack:\r\n",
        "                      inputs, labels = data\r\n",
        "                    else:\r\n",
        "                      inputs, labels, idx = data\r\n",
        "                    \r\n",
        "                    inputs = inputs.to(device)\r\n",
        "                    labels = labels.to(device)\r\n",
        "                    optimizer.zero_grad()\r\n",
        "                    with torch.set_grad_enabled(False):\r\n",
        "                        outputs = model(inputs)\r\n",
        "                        _, preds = torch.max(outputs, 1)\r\n",
        "                        \r\n",
        "                        loss = criterion(outputs, labels)\r\n",
        "                \r\n",
        "                    running_loss += loss.item() * inputs.size(0)\r\n",
        "                    running_corrects += torch.sum(preds == labels.data)\r\n",
        "                \r\n",
        "                epoch_loss = running_loss / test_size\r\n",
        "                epoch_acc = running_corrects.double() / test_size\r\n",
        "                \r\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format('Val', epoch_loss, epoch_acc))\r\n",
        "                if epoch_acc > best_acc:\r\n",
        "                    best_acc = epoch_acc\r\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "\r\n",
        "                last_model_wts = copy.deepcopy(model.state_dict())\r\n",
        "\r\n",
        "        print()\r\n",
        "\r\n",
        "    time_elapsed = time.time() - since\r\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\r\n",
        "\r\n",
        "    # load best model weights\r\n",
        "    model.load_state_dict(best_model_wts)\r\n",
        "    \r\n",
        "    return model, best_acc, last_model_wts"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtm1mVUe7qdH"
      },
      "source": [
        "\"\"\" Returns top3 prediction probability given x\"\"\"\r\n",
        "\r\n",
        "def test(model, test_loader, criterion):\r\n",
        "  model.eval()   # Set model to evaluate mode\r\n",
        "                \r\n",
        "  running_loss = 0.0\r\n",
        "  running_corrects = 0\r\n",
        "  # prediction_list = []\r\n",
        "  i = 0\r\n",
        "  for data in test_loader:\r\n",
        "      inputs, labels, idx = data\r\n",
        "      inputs = inputs.to(device)\r\n",
        "      labels = labels.to(device)\r\n",
        "     \r\n",
        "      with torch.set_grad_enabled(False):\r\n",
        "          outputs = model(inputs)\r\n",
        "          _, preds = torch.max(outputs, 1)\r\n",
        "          sm = torch.nn.Softmax()\r\n",
        "          pred_probs = sm(outputs)\r\n",
        "          pred_probs, indices = torch.sort(pred_probs, descending=True)\r\n",
        "          # print(pred_probs)\r\n",
        "          if i == 0:\r\n",
        "            prediction_list = pred_probs[:,0:3]\r\n",
        "          else:\r\n",
        "            prediction_list = torch.cat((prediction_list, pred_probs[:,0:3]))\r\n",
        "          i += 1\r\n",
        "          loss = criterion(outputs, labels)\r\n",
        "\r\n",
        "      running_loss += loss.item() * inputs.size(0)\r\n",
        "      running_corrects += torch.sum(preds == labels.data)\r\n",
        "\r\n",
        "  epoch_loss = running_loss / test_size\r\n",
        "  epoch_acc = running_corrects.double() / test_size\r\n",
        "\r\n",
        "  print('{} Loss: {:.4f} Acc: {:.4f}'.format('Val', epoch_loss, epoch_acc))\r\n",
        "  \r\n",
        "  return prediction_list"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLc1fCSSbq7D"
      },
      "source": [
        "\"\"\" Attack model test function \"\"\"\r\n",
        "def attack_test(model, test_loader, criterion):\r\n",
        "  model.eval()   # Set model to evaluate mode\r\n",
        "                \r\n",
        "  running_loss = 0.0\r\n",
        "  running_corrects = 0\r\n",
        "  # prediction_list = []\r\n",
        "  i = 0\r\n",
        "  test_true_label = []\r\n",
        "  test_pred_label = []\r\n",
        "  for data in test_loader:\r\n",
        "      inputs, labels = data\r\n",
        "      inputs = inputs.to(device)\r\n",
        "      labels = labels.to(device)\r\n",
        "      \r\n",
        "      with torch.set_grad_enabled(False):\r\n",
        "          outputs = model(inputs)\r\n",
        "          _, preds = torch.max(outputs, 1)\r\n",
        "          sm = torch.nn.Softmax()\r\n",
        "          pred_probs = sm(outputs)\r\n",
        "          pred_probs, indices = torch.sort(pred_probs, descending=True)\r\n",
        "          loss = criterion(outputs, labels)\r\n",
        "\r\n",
        "          test_true_label.append(labels.data)\r\n",
        "          test_pred_label.append(preds.data)\r\n",
        "      running_loss += loss.item() * inputs.size(0)\r\n",
        "      running_corrects += torch.sum(preds == labels.data)\r\n",
        "\r\n",
        "  epoch_loss = running_loss / test_size\r\n",
        "  epoch_acc = running_corrects.double() / test_size\r\n",
        "\r\n",
        "  print('{} Loss: {:.4f} Acc: {:.4f}'.format('Val', epoch_loss, epoch_acc))\r\n",
        "  \r\n",
        "  return test_true_label, test_pred_label"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhIS35qQedVo",
        "outputId": "eea7e5f2-6147-44dc-9182-288afe37155d"
      },
      "source": [
        "\"\"\" Train Shadow Model \"\"\"\r\n",
        "\r\n",
        "print(\"Training Shadow Model\")\r\n",
        "train_size = len(shadow_train)\r\n",
        "test_size = len(shadow_test)\r\n",
        "print(train_size, test_size)\r\n",
        "shadow_net = Shadow_LeNet().to(device)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# Observe that all parameters are being optimized\r\n",
        "# optimizer_ft = optim.Adam(shadow_net.parameters(), lr=0.001, weight_decay=1e-07)\r\n",
        "optimizer_ft = optim.SGD(shadow_net.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-07)\r\n",
        "\r\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=20, gamma=0.1)\r\n",
        "\r\n",
        "best_net, best_acc, last_net = train_model(shadow_net, shadow_train_loader, shadow_test_loader, criterion, optimizer_ft, exp_lr_scheduler,\r\n",
        "                        num_epochs=60)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Shadow Model\n",
            "12500 12500\n",
            "Epoch 0/59\n",
            "----------\n",
            "tensor(185)\n",
            "Train Loss: 4.5949 Acc: 0.0148\n",
            "Val Loss: 4.5479 Acc: 0.0171\n",
            "\n",
            "Epoch 1/59\n",
            "----------\n",
            "tensor(431)\n",
            "Train Loss: 4.3632 Acc: 0.0345\n",
            "Val Loss: 4.1941 Acc: 0.0471\n",
            "\n",
            "Epoch 2/59\n",
            "----------\n",
            "tensor(861)\n",
            "Train Loss: 4.0832 Acc: 0.0689\n",
            "Val Loss: 4.0292 Acc: 0.0754\n",
            "\n",
            "Epoch 3/59\n",
            "----------\n",
            "tensor(1157)\n",
            "Train Loss: 3.9305 Acc: 0.0926\n",
            "Val Loss: 3.9190 Acc: 0.1008\n",
            "\n",
            "Epoch 4/59\n",
            "----------\n",
            "tensor(1405)\n",
            "Train Loss: 3.8048 Acc: 0.1124\n",
            "Val Loss: 3.8204 Acc: 0.1081\n",
            "\n",
            "Epoch 5/59\n",
            "----------\n",
            "tensor(1684)\n",
            "Train Loss: 3.6576 Acc: 0.1347\n",
            "Val Loss: 3.7178 Acc: 0.1333\n",
            "\n",
            "Epoch 6/59\n",
            "----------\n",
            "tensor(1950)\n",
            "Train Loss: 3.5242 Acc: 0.1560\n",
            "Val Loss: 3.6027 Acc: 0.1518\n",
            "\n",
            "Epoch 7/59\n",
            "----------\n",
            "tensor(2244)\n",
            "Train Loss: 3.4042 Acc: 0.1795\n",
            "Val Loss: 3.5590 Acc: 0.1589\n",
            "\n",
            "Epoch 8/59\n",
            "----------\n",
            "tensor(2387)\n",
            "Train Loss: 3.2990 Acc: 0.1910\n",
            "Val Loss: 3.5768 Acc: 0.1598\n",
            "\n",
            "Epoch 9/59\n",
            "----------\n",
            "tensor(2674)\n",
            "Train Loss: 3.2087 Acc: 0.2139\n",
            "Val Loss: 3.4611 Acc: 0.1786\n",
            "\n",
            "Epoch 10/59\n",
            "----------\n",
            "tensor(2853)\n",
            "Train Loss: 3.1227 Acc: 0.2282\n",
            "Val Loss: 3.4541 Acc: 0.1870\n",
            "\n",
            "Epoch 11/59\n",
            "----------\n",
            "tensor(3032)\n",
            "Train Loss: 3.0240 Acc: 0.2426\n",
            "Val Loss: 3.5223 Acc: 0.1858\n",
            "\n",
            "Epoch 12/59\n",
            "----------\n",
            "tensor(3238)\n",
            "Train Loss: 2.9405 Acc: 0.2590\n",
            "Val Loss: 3.4441 Acc: 0.1918\n",
            "\n",
            "Epoch 13/59\n",
            "----------\n",
            "tensor(3448)\n",
            "Train Loss: 2.8612 Acc: 0.2758\n",
            "Val Loss: 3.4311 Acc: 0.1961\n",
            "\n",
            "Epoch 14/59\n",
            "----------\n",
            "tensor(3736)\n",
            "Train Loss: 2.7573 Acc: 0.2989\n",
            "Val Loss: 3.4998 Acc: 0.1982\n",
            "\n",
            "Epoch 15/59\n",
            "----------\n",
            "tensor(3892)\n",
            "Train Loss: 2.6813 Acc: 0.3114\n",
            "Val Loss: 3.5745 Acc: 0.1973\n",
            "\n",
            "Epoch 16/59\n",
            "----------\n",
            "tensor(4028)\n",
            "Train Loss: 2.6188 Acc: 0.3222\n",
            "Val Loss: 3.5428 Acc: 0.1938\n",
            "\n",
            "Epoch 17/59\n",
            "----------\n",
            "tensor(4223)\n",
            "Train Loss: 2.5381 Acc: 0.3378\n",
            "Val Loss: 3.6782 Acc: 0.1880\n",
            "\n",
            "Epoch 18/59\n",
            "----------\n",
            "tensor(4395)\n",
            "Train Loss: 2.4770 Acc: 0.3516\n",
            "Val Loss: 3.6613 Acc: 0.1875\n",
            "\n",
            "Epoch 19/59\n",
            "----------\n",
            "tensor(4546)\n",
            "Train Loss: 2.4116 Acc: 0.3637\n",
            "Val Loss: 3.6821 Acc: 0.1943\n",
            "\n",
            "Epoch 20/59\n",
            "----------\n",
            "tensor(6317)\n",
            "Train Loss: 1.8468 Acc: 0.5054\n",
            "Val Loss: 3.8023 Acc: 0.2191\n",
            "\n",
            "Epoch 21/59\n",
            "----------\n",
            "tensor(6783)\n",
            "Train Loss: 1.6954 Acc: 0.5426\n",
            "Val Loss: 3.9099 Acc: 0.2198\n",
            "\n",
            "Epoch 22/59\n",
            "----------\n",
            "tensor(6992)\n",
            "Train Loss: 1.6299 Acc: 0.5594\n",
            "Val Loss: 3.9480 Acc: 0.2178\n",
            "\n",
            "Epoch 23/59\n",
            "----------\n",
            "tensor(7158)\n",
            "Train Loss: 1.5794 Acc: 0.5726\n",
            "Val Loss: 4.0104 Acc: 0.2181\n",
            "\n",
            "Epoch 24/59\n",
            "----------\n",
            "tensor(7316)\n",
            "Train Loss: 1.5366 Acc: 0.5853\n",
            "Val Loss: 4.0914 Acc: 0.2134\n",
            "\n",
            "Epoch 25/59\n",
            "----------\n",
            "tensor(7438)\n",
            "Train Loss: 1.4956 Acc: 0.5950\n",
            "Val Loss: 4.1501 Acc: 0.2122\n",
            "\n",
            "Epoch 26/59\n",
            "----------\n",
            "tensor(7503)\n",
            "Train Loss: 1.4601 Acc: 0.6002\n",
            "Val Loss: 4.2235 Acc: 0.2141\n",
            "\n",
            "Epoch 27/59\n",
            "----------\n",
            "tensor(7672)\n",
            "Train Loss: 1.4246 Acc: 0.6138\n",
            "Val Loss: 4.3110 Acc: 0.2110\n",
            "\n",
            "Epoch 28/59\n",
            "----------\n",
            "tensor(7784)\n",
            "Train Loss: 1.3948 Acc: 0.6227\n",
            "Val Loss: 4.3777 Acc: 0.2109\n",
            "\n",
            "Epoch 29/59\n",
            "----------\n",
            "tensor(7916)\n",
            "Train Loss: 1.3580 Acc: 0.6333\n",
            "Val Loss: 4.4376 Acc: 0.2089\n",
            "\n",
            "Epoch 30/59\n",
            "----------\n",
            "tensor(8017)\n",
            "Train Loss: 1.3255 Acc: 0.6414\n",
            "Val Loss: 4.4849 Acc: 0.2094\n",
            "\n",
            "Epoch 31/59\n",
            "----------\n",
            "tensor(8081)\n",
            "Train Loss: 1.2953 Acc: 0.6465\n",
            "Val Loss: 4.5806 Acc: 0.2100\n",
            "\n",
            "Epoch 32/59\n",
            "----------\n",
            "tensor(8237)\n",
            "Train Loss: 1.2610 Acc: 0.6590\n",
            "Val Loss: 4.6383 Acc: 0.2071\n",
            "\n",
            "Epoch 33/59\n",
            "----------\n",
            "tensor(8320)\n",
            "Train Loss: 1.2313 Acc: 0.6656\n",
            "Val Loss: 4.7407 Acc: 0.2067\n",
            "\n",
            "Epoch 34/59\n",
            "----------\n",
            "tensor(8400)\n",
            "Train Loss: 1.2030 Acc: 0.6720\n",
            "Val Loss: 4.7395 Acc: 0.2017\n",
            "\n",
            "Epoch 35/59\n",
            "----------\n",
            "tensor(8574)\n",
            "Train Loss: 1.1714 Acc: 0.6859\n",
            "Val Loss: 4.9015 Acc: 0.2044\n",
            "\n",
            "Epoch 36/59\n",
            "----------\n",
            "tensor(8673)\n",
            "Train Loss: 1.1408 Acc: 0.6938\n",
            "Val Loss: 4.9698 Acc: 0.2021\n",
            "\n",
            "Epoch 37/59\n",
            "----------\n",
            "tensor(8769)\n",
            "Train Loss: 1.1139 Acc: 0.7015\n",
            "Val Loss: 5.0727 Acc: 0.2042\n",
            "\n",
            "Epoch 38/59\n",
            "----------\n",
            "tensor(8807)\n",
            "Train Loss: 1.0840 Acc: 0.7046\n",
            "Val Loss: 5.1692 Acc: 0.2033\n",
            "\n",
            "Epoch 39/59\n",
            "----------\n",
            "tensor(8946)\n",
            "Train Loss: 1.0522 Acc: 0.7157\n",
            "Val Loss: 5.2384 Acc: 0.2007\n",
            "\n",
            "Epoch 40/59\n",
            "----------\n",
            "tensor(9438)\n",
            "Train Loss: 0.9460 Acc: 0.7550\n",
            "Val Loss: 5.2721 Acc: 0.2035\n",
            "\n",
            "Epoch 41/59\n",
            "----------\n",
            "tensor(9533)\n",
            "Train Loss: 0.9282 Acc: 0.7626\n",
            "Val Loss: 5.2993 Acc: 0.2025\n",
            "\n",
            "Epoch 42/59\n",
            "----------\n",
            "tensor(9554)\n",
            "Train Loss: 0.9216 Acc: 0.7643\n",
            "Val Loss: 5.3155 Acc: 0.2023\n",
            "\n",
            "Epoch 43/59\n",
            "----------\n",
            "tensor(9567)\n",
            "Train Loss: 0.9167 Acc: 0.7654\n",
            "Val Loss: 5.3467 Acc: 0.2028\n",
            "\n",
            "Epoch 44/59\n",
            "----------\n",
            "tensor(9592)\n",
            "Train Loss: 0.9123 Acc: 0.7674\n",
            "Val Loss: 5.3650 Acc: 0.2030\n",
            "\n",
            "Epoch 45/59\n",
            "----------\n",
            "tensor(9617)\n",
            "Train Loss: 0.9086 Acc: 0.7694\n",
            "Val Loss: 5.3797 Acc: 0.2030\n",
            "\n",
            "Epoch 46/59\n",
            "----------\n",
            "tensor(9619)\n",
            "Train Loss: 0.9046 Acc: 0.7695\n",
            "Val Loss: 5.3941 Acc: 0.2031\n",
            "\n",
            "Epoch 47/59\n",
            "----------\n",
            "tensor(9640)\n",
            "Train Loss: 0.9007 Acc: 0.7712\n",
            "Val Loss: 5.4120 Acc: 0.2027\n",
            "\n",
            "Epoch 48/59\n",
            "----------\n",
            "tensor(9628)\n",
            "Train Loss: 0.8971 Acc: 0.7702\n",
            "Val Loss: 5.4345 Acc: 0.2030\n",
            "\n",
            "Epoch 49/59\n",
            "----------\n",
            "tensor(9651)\n",
            "Train Loss: 0.8936 Acc: 0.7721\n",
            "Val Loss: 5.4395 Acc: 0.2026\n",
            "\n",
            "Epoch 50/59\n",
            "----------\n",
            "tensor(9672)\n",
            "Train Loss: 0.8902 Acc: 0.7738\n",
            "Val Loss: 5.4535 Acc: 0.2018\n",
            "\n",
            "Epoch 51/59\n",
            "----------\n",
            "tensor(9682)\n",
            "Train Loss: 0.8865 Acc: 0.7746\n",
            "Val Loss: 5.4855 Acc: 0.2027\n",
            "\n",
            "Epoch 52/59\n",
            "----------\n",
            "tensor(9696)\n",
            "Train Loss: 0.8832 Acc: 0.7757\n",
            "Val Loss: 5.4896 Acc: 0.2026\n",
            "\n",
            "Epoch 53/59\n",
            "----------\n",
            "tensor(9704)\n",
            "Train Loss: 0.8798 Acc: 0.7763\n",
            "Val Loss: 5.5011 Acc: 0.2024\n",
            "\n",
            "Epoch 54/59\n",
            "----------\n",
            "tensor(9730)\n",
            "Train Loss: 0.8760 Acc: 0.7784\n",
            "Val Loss: 5.5116 Acc: 0.2033\n",
            "\n",
            "Epoch 55/59\n",
            "----------\n",
            "tensor(9743)\n",
            "Train Loss: 0.8728 Acc: 0.7794\n",
            "Val Loss: 5.5284 Acc: 0.2014\n",
            "\n",
            "Epoch 56/59\n",
            "----------\n",
            "tensor(9755)\n",
            "Train Loss: 0.8693 Acc: 0.7804\n",
            "Val Loss: 5.5395 Acc: 0.2017\n",
            "\n",
            "Epoch 57/59\n",
            "----------\n",
            "tensor(9775)\n",
            "Train Loss: 0.8659 Acc: 0.7820\n",
            "Val Loss: 5.5603 Acc: 0.2024\n",
            "\n",
            "Epoch 58/59\n",
            "----------\n",
            "tensor(9789)\n",
            "Train Loss: 0.8620 Acc: 0.7831\n",
            "Val Loss: 5.5786 Acc: 0.2010\n",
            "\n",
            "Epoch 59/59\n",
            "----------\n",
            "tensor(9795)\n",
            "Train Loss: 0.8590 Acc: 0.7836\n",
            "Val Loss: 5.5835 Acc: 0.2014\n",
            "\n",
            "Training complete in 11m 25s\n",
            "Best val Acc: 0.219760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DqP-xlHd-py",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9dbc7e2-2cd4-44b2-9992-90aa01be24c4"
      },
      "source": [
        "print(\"Training Base Shadow Model\")\r\n",
        "train_size = len(shadow_train)\r\n",
        "test_size = len(shadow_test)\r\n",
        "print(train_size, test_size)\r\n",
        "base_shadow_net = Base_Shadow_LeNet().to(device)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# Observe that all parameters are being optimized\r\n",
        "# base_optimizer_ft = optim.Adam(base_shadow_net.parameters(), lr=0.001, weight_decay=1e-07)\r\n",
        "base_optimizer_ft = optim.SGD(base_shadow_net.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-07)\r\n",
        "\r\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "base_exp_lr_scheduler = lr_scheduler.StepLR(base_optimizer_ft, step_size=20, gamma=0.1)\r\n",
        "\r\n",
        "best_base_net, best_base_acc, last_base_net = train_model(base_shadow_net, shadow_train_loader, shadow_test_loader, criterion, base_optimizer_ft, base_exp_lr_scheduler,\r\n",
        "                        num_epochs=60)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Base Shadow Model\n",
            "12500 12500\n",
            "Epoch 0/59\n",
            "----------\n",
            "tensor(191)\n",
            "Train Loss: 4.5957 Acc: 0.0153\n",
            "Val Loss: 4.5453 Acc: 0.0274\n",
            "\n",
            "Epoch 1/59\n",
            "----------\n",
            "tensor(597)\n",
            "Train Loss: 4.3452 Acc: 0.0478\n",
            "Val Loss: 4.1805 Acc: 0.0647\n",
            "\n",
            "Epoch 2/59\n",
            "----------\n",
            "tensor(1042)\n",
            "Train Loss: 4.0128 Acc: 0.0834\n",
            "Val Loss: 4.0005 Acc: 0.0855\n",
            "\n",
            "Epoch 3/59\n",
            "----------\n",
            "tensor(1318)\n",
            "Train Loss: 3.8380 Acc: 0.1054\n",
            "Val Loss: 3.9313 Acc: 0.0930\n",
            "\n",
            "Epoch 4/59\n",
            "----------\n",
            "tensor(1581)\n",
            "Train Loss: 3.6982 Acc: 0.1265\n",
            "Val Loss: 3.7442 Acc: 0.1335\n",
            "\n",
            "Epoch 5/59\n",
            "----------\n",
            "tensor(1857)\n",
            "Train Loss: 3.5589 Acc: 0.1486\n",
            "Val Loss: 3.6722 Acc: 0.1350\n",
            "\n",
            "Epoch 6/59\n",
            "----------\n",
            "tensor(2033)\n",
            "Train Loss: 3.4640 Acc: 0.1626\n",
            "Val Loss: 3.5956 Acc: 0.1494\n",
            "\n",
            "Epoch 7/59\n",
            "----------\n",
            "tensor(2299)\n",
            "Train Loss: 3.3542 Acc: 0.1839\n",
            "Val Loss: 3.5452 Acc: 0.1662\n",
            "\n",
            "Epoch 8/59\n",
            "----------\n",
            "tensor(2447)\n",
            "Train Loss: 3.2475 Acc: 0.1958\n",
            "Val Loss: 3.5047 Acc: 0.1681\n",
            "\n",
            "Epoch 9/59\n",
            "----------\n",
            "tensor(2776)\n",
            "Train Loss: 3.1418 Acc: 0.2221\n",
            "Val Loss: 3.5411 Acc: 0.1689\n",
            "\n",
            "Epoch 10/59\n",
            "----------\n",
            "tensor(2974)\n",
            "Train Loss: 3.0578 Acc: 0.2379\n",
            "Val Loss: 3.4867 Acc: 0.1727\n",
            "\n",
            "Epoch 11/59\n",
            "----------\n",
            "tensor(3190)\n",
            "Train Loss: 2.9543 Acc: 0.2552\n",
            "Val Loss: 3.5146 Acc: 0.1791\n",
            "\n",
            "Epoch 12/59\n",
            "----------\n",
            "tensor(3388)\n",
            "Train Loss: 2.8681 Acc: 0.2710\n",
            "Val Loss: 3.4939 Acc: 0.1782\n",
            "\n",
            "Epoch 13/59\n",
            "----------\n",
            "tensor(3597)\n",
            "Train Loss: 2.7852 Acc: 0.2878\n",
            "Val Loss: 3.5535 Acc: 0.1802\n",
            "\n",
            "Epoch 14/59\n",
            "----------\n",
            "tensor(3829)\n",
            "Train Loss: 2.6977 Acc: 0.3063\n",
            "Val Loss: 3.5471 Acc: 0.1863\n",
            "\n",
            "Epoch 15/59\n",
            "----------\n",
            "tensor(3961)\n",
            "Train Loss: 2.6232 Acc: 0.3169\n",
            "Val Loss: 3.6056 Acc: 0.1811\n",
            "\n",
            "Epoch 16/59\n",
            "----------\n",
            "tensor(4260)\n",
            "Train Loss: 2.5275 Acc: 0.3408\n",
            "Val Loss: 3.7133 Acc: 0.1800\n",
            "\n",
            "Epoch 17/59\n",
            "----------\n",
            "tensor(4501)\n",
            "Train Loss: 2.4275 Acc: 0.3601\n",
            "Val Loss: 3.7195 Acc: 0.1875\n",
            "\n",
            "Epoch 18/59\n",
            "----------\n",
            "tensor(4686)\n",
            "Train Loss: 2.3568 Acc: 0.3749\n",
            "Val Loss: 3.9555 Acc: 0.1767\n",
            "\n",
            "Epoch 19/59\n",
            "----------\n",
            "tensor(4804)\n",
            "Train Loss: 2.3021 Acc: 0.3843\n",
            "Val Loss: 3.8540 Acc: 0.1776\n",
            "\n",
            "Epoch 20/59\n",
            "----------\n",
            "tensor(6662)\n",
            "Train Loss: 1.7296 Acc: 0.5330\n",
            "Val Loss: 4.0719 Acc: 0.2030\n",
            "\n",
            "Epoch 21/59\n",
            "----------\n",
            "tensor(7213)\n",
            "Train Loss: 1.5571 Acc: 0.5770\n",
            "Val Loss: 4.1806 Acc: 0.1992\n",
            "\n",
            "Epoch 22/59\n",
            "----------\n",
            "tensor(7428)\n",
            "Train Loss: 1.4860 Acc: 0.5942\n",
            "Val Loss: 4.2708 Acc: 0.1988\n",
            "\n",
            "Epoch 23/59\n",
            "----------\n",
            "tensor(7634)\n",
            "Train Loss: 1.4330 Acc: 0.6107\n",
            "Val Loss: 4.3667 Acc: 0.1979\n",
            "\n",
            "Epoch 24/59\n",
            "----------\n",
            "tensor(7768)\n",
            "Train Loss: 1.3856 Acc: 0.6214\n",
            "Val Loss: 4.4815 Acc: 0.1980\n",
            "\n",
            "Epoch 25/59\n",
            "----------\n",
            "tensor(7881)\n",
            "Train Loss: 1.3448 Acc: 0.6305\n",
            "Val Loss: 4.5214 Acc: 0.1963\n",
            "\n",
            "Epoch 26/59\n",
            "----------\n",
            "tensor(8062)\n",
            "Train Loss: 1.3052 Acc: 0.6450\n",
            "Val Loss: 4.6259 Acc: 0.1959\n",
            "\n",
            "Epoch 27/59\n",
            "----------\n",
            "tensor(8190)\n",
            "Train Loss: 1.2654 Acc: 0.6552\n",
            "Val Loss: 4.6986 Acc: 0.1943\n",
            "\n",
            "Epoch 28/59\n",
            "----------\n",
            "tensor(8325)\n",
            "Train Loss: 1.2311 Acc: 0.6660\n",
            "Val Loss: 4.7626 Acc: 0.1934\n",
            "\n",
            "Epoch 29/59\n",
            "----------\n",
            "tensor(8442)\n",
            "Train Loss: 1.1945 Acc: 0.6754\n",
            "Val Loss: 4.8873 Acc: 0.1906\n",
            "\n",
            "Epoch 30/59\n",
            "----------\n",
            "tensor(8545)\n",
            "Train Loss: 1.1587 Acc: 0.6836\n",
            "Val Loss: 5.0088 Acc: 0.1908\n",
            "\n",
            "Epoch 31/59\n",
            "----------\n",
            "tensor(8677)\n",
            "Train Loss: 1.1269 Acc: 0.6942\n",
            "Val Loss: 5.0805 Acc: 0.1879\n",
            "\n",
            "Epoch 32/59\n",
            "----------\n",
            "tensor(8803)\n",
            "Train Loss: 1.0945 Acc: 0.7042\n",
            "Val Loss: 5.1399 Acc: 0.1896\n",
            "\n",
            "Epoch 33/59\n",
            "----------\n",
            "tensor(8926)\n",
            "Train Loss: 1.0605 Acc: 0.7141\n",
            "Val Loss: 5.2427 Acc: 0.1886\n",
            "\n",
            "Epoch 34/59\n",
            "----------\n",
            "tensor(9035)\n",
            "Train Loss: 1.0290 Acc: 0.7228\n",
            "Val Loss: 5.4142 Acc: 0.1892\n",
            "\n",
            "Epoch 35/59\n",
            "----------\n",
            "tensor(9150)\n",
            "Train Loss: 1.0010 Acc: 0.7320\n",
            "Val Loss: 5.5030 Acc: 0.1863\n",
            "\n",
            "Epoch 36/59\n",
            "----------\n",
            "tensor(9315)\n",
            "Train Loss: 0.9640 Acc: 0.7452\n",
            "Val Loss: 5.5994 Acc: 0.1847\n",
            "\n",
            "Epoch 37/59\n",
            "----------\n",
            "tensor(9369)\n",
            "Train Loss: 0.9389 Acc: 0.7495\n",
            "Val Loss: 5.7093 Acc: 0.1858\n",
            "\n",
            "Epoch 38/59\n",
            "----------\n",
            "tensor(9500)\n",
            "Train Loss: 0.9095 Acc: 0.7600\n",
            "Val Loss: 5.8173 Acc: 0.1852\n",
            "\n",
            "Epoch 39/59\n",
            "----------\n",
            "tensor(9593)\n",
            "Train Loss: 0.8777 Acc: 0.7674\n",
            "Val Loss: 6.0208 Acc: 0.1817\n",
            "\n",
            "Epoch 40/59\n",
            "----------\n",
            "tensor(10119)\n",
            "Train Loss: 0.7726 Acc: 0.8095\n",
            "Val Loss: 6.0164 Acc: 0.1850\n",
            "\n",
            "Epoch 41/59\n",
            "----------\n",
            "tensor(10202)\n",
            "Train Loss: 0.7546 Acc: 0.8162\n",
            "Val Loss: 6.0429 Acc: 0.1851\n",
            "\n",
            "Epoch 42/59\n",
            "----------\n",
            "tensor(10236)\n",
            "Train Loss: 0.7478 Acc: 0.8189\n",
            "Val Loss: 6.0648 Acc: 0.1850\n",
            "\n",
            "Epoch 43/59\n",
            "----------\n",
            "tensor(10240)\n",
            "Train Loss: 0.7431 Acc: 0.8192\n",
            "Val Loss: 6.0877 Acc: 0.1862\n",
            "\n",
            "Epoch 44/59\n",
            "----------\n",
            "tensor(10265)\n",
            "Train Loss: 0.7389 Acc: 0.8212\n",
            "Val Loss: 6.1060 Acc: 0.1858\n",
            "\n",
            "Epoch 45/59\n",
            "----------\n",
            "tensor(10279)\n",
            "Train Loss: 0.7351 Acc: 0.8223\n",
            "Val Loss: 6.1374 Acc: 0.1858\n",
            "\n",
            "Epoch 46/59\n",
            "----------\n",
            "tensor(10278)\n",
            "Train Loss: 0.7310 Acc: 0.8222\n",
            "Val Loss: 6.1483 Acc: 0.1851\n",
            "\n",
            "Epoch 47/59\n",
            "----------\n",
            "tensor(10304)\n",
            "Train Loss: 0.7275 Acc: 0.8243\n",
            "Val Loss: 6.1780 Acc: 0.1858\n",
            "\n",
            "Epoch 48/59\n",
            "----------\n",
            "tensor(10311)\n",
            "Train Loss: 0.7240 Acc: 0.8249\n",
            "Val Loss: 6.1971 Acc: 0.1856\n",
            "\n",
            "Epoch 49/59\n",
            "----------\n",
            "tensor(10329)\n",
            "Train Loss: 0.7200 Acc: 0.8263\n",
            "Val Loss: 6.2195 Acc: 0.1854\n",
            "\n",
            "Epoch 50/59\n",
            "----------\n",
            "tensor(10338)\n",
            "Train Loss: 0.7169 Acc: 0.8270\n",
            "Val Loss: 6.2288 Acc: 0.1854\n",
            "\n",
            "Epoch 51/59\n",
            "----------\n",
            "tensor(10334)\n",
            "Train Loss: 0.7132 Acc: 0.8267\n",
            "Val Loss: 6.2560 Acc: 0.1857\n",
            "\n",
            "Epoch 52/59\n",
            "----------\n",
            "tensor(10347)\n",
            "Train Loss: 0.7100 Acc: 0.8278\n",
            "Val Loss: 6.2711 Acc: 0.1854\n",
            "\n",
            "Epoch 53/59\n",
            "----------\n",
            "tensor(10366)\n",
            "Train Loss: 0.7066 Acc: 0.8293\n",
            "Val Loss: 6.2896 Acc: 0.1846\n",
            "\n",
            "Epoch 54/59\n",
            "----------\n",
            "tensor(10384)\n",
            "Train Loss: 0.7033 Acc: 0.8307\n",
            "Val Loss: 6.3102 Acc: 0.1849\n",
            "\n",
            "Epoch 55/59\n",
            "----------\n",
            "tensor(10388)\n",
            "Train Loss: 0.7001 Acc: 0.8310\n",
            "Val Loss: 6.3239 Acc: 0.1858\n",
            "\n",
            "Epoch 56/59\n",
            "----------\n",
            "tensor(10393)\n",
            "Train Loss: 0.6969 Acc: 0.8314\n",
            "Val Loss: 6.3479 Acc: 0.1851\n",
            "\n",
            "Epoch 57/59\n",
            "----------\n",
            "tensor(10424)\n",
            "Train Loss: 0.6934 Acc: 0.8339\n",
            "Val Loss: 6.3621 Acc: 0.1841\n",
            "\n",
            "Epoch 58/59\n",
            "----------\n",
            "tensor(10429)\n",
            "Train Loss: 0.6903 Acc: 0.8343\n",
            "Val Loss: 6.3872 Acc: 0.1842\n",
            "\n",
            "Epoch 59/59\n",
            "----------\n",
            "tensor(10444)\n",
            "Train Loss: 0.6869 Acc: 0.8355\n",
            "Val Loss: 6.3963 Acc: 0.1838\n",
            "\n",
            "Training complete in 11m 42s\n",
            "Best val Acc: 0.203040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YVuWzHO8nr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224eb59e-73e8-4d64-aa8e-b68d3148828b"
      },
      "source": [
        "\"\"\" Train ResNet Shadow \"\"\"\r\n",
        "\r\n",
        "print(\"Training ResNet Shadow\")\r\n",
        "train_size = len(shadow_train)\r\n",
        "test_size = len(shadow_test)\r\n",
        "print(train_size, test_size)\r\n",
        "resnet_shadow = Resnet_Shadow.to(device)\r\n",
        "# loading pretrained model\r\n",
        "#     net = torch.load('LeNet_5_class_pretrained_model.tar')\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# Observe that all parameters are being optimized\r\n",
        "# resnet_optimizer_ft = optim.Adam(resnet_shadow.parameters(), lr=0.001, weight_decay=1e-07)\r\n",
        "resnet_optimizer_ft = optim.SGD(resnet_shadow.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-07)\r\n",
        "\r\n",
        "\r\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "resnet_exp_lr_scheduler = lr_scheduler.StepLR(resnet_optimizer_ft, step_size=20, gamma=0.1)\r\n",
        "\r\n",
        "resnet_best_net, resnet_best_acc, resnet_last_net = train_model(resnet_shadow, shadow_train_loader, shadow_test_loader, criterion, resnet_optimizer_ft, resnet_exp_lr_scheduler,\r\n",
        "                        num_epochs=25)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training ResNet Shadow\n",
            "12500 12500\n",
            "Epoch 0/24\n",
            "----------\n",
            "tensor(963)\n",
            "Train Loss: 4.3985 Acc: 0.0770\n",
            "Val Loss: 3.9486 Acc: 0.1080\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "tensor(1958)\n",
            "Train Loss: 3.5944 Acc: 0.1566\n",
            "Val Loss: 3.6702 Acc: 0.1498\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "tensor(2681)\n",
            "Train Loss: 3.2048 Acc: 0.2145\n",
            "Val Loss: 3.4698 Acc: 0.1785\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "tensor(3422)\n",
            "Train Loss: 2.8861 Acc: 0.2738\n",
            "Val Loss: 3.3869 Acc: 0.2028\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "tensor(4189)\n",
            "Train Loss: 2.5478 Acc: 0.3351\n",
            "Val Loss: 3.3602 Acc: 0.2260\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "tensor(5067)\n",
            "Train Loss: 2.2231 Acc: 0.4054\n",
            "Val Loss: 3.4341 Acc: 0.2279\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "tensor(6141)\n",
            "Train Loss: 1.8463 Acc: 0.4913\n",
            "Val Loss: 3.6073 Acc: 0.2360\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "tensor(7222)\n",
            "Train Loss: 1.4896 Acc: 0.5778\n",
            "Val Loss: 3.7608 Acc: 0.2366\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "tensor(8221)\n",
            "Train Loss: 1.1750 Acc: 0.6577\n",
            "Val Loss: 4.0329 Acc: 0.2370\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "tensor(9173)\n",
            "Train Loss: 0.8858 Acc: 0.7338\n",
            "Val Loss: 4.3353 Acc: 0.2421\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "tensor(9901)\n",
            "Train Loss: 0.6786 Acc: 0.7921\n",
            "Val Loss: 4.4376 Acc: 0.2430\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "tensor(10661)\n",
            "Train Loss: 0.4776 Acc: 0.8529\n",
            "Val Loss: 4.5870 Acc: 0.2454\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "tensor(11275)\n",
            "Train Loss: 0.3183 Acc: 0.9020\n",
            "Val Loss: 4.7679 Acc: 0.2494\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "tensor(11626)\n",
            "Train Loss: 0.2254 Acc: 0.9301\n",
            "Val Loss: 4.9052 Acc: 0.2462\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "tensor(11895)\n",
            "Train Loss: 0.1636 Acc: 0.9516\n",
            "Val Loss: 5.0270 Acc: 0.2578\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "tensor(12110)\n",
            "Train Loss: 0.1112 Acc: 0.9688\n",
            "Val Loss: 5.0655 Acc: 0.2592\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "tensor(12265)\n",
            "Train Loss: 0.0704 Acc: 0.9812\n",
            "Val Loss: 5.1245 Acc: 0.2630\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "tensor(12393)\n",
            "Train Loss: 0.0389 Acc: 0.9914\n",
            "Val Loss: 5.1205 Acc: 0.2677\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "tensor(12454)\n",
            "Train Loss: 0.0206 Acc: 0.9963\n",
            "Val Loss: 5.1188 Acc: 0.2674\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "tensor(12464)\n",
            "Train Loss: 0.0164 Acc: 0.9971\n",
            "Val Loss: 5.1058 Acc: 0.2782\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "tensor(12489)\n",
            "Train Loss: 0.0066 Acc: 0.9991\n",
            "Val Loss: 5.0673 Acc: 0.2800\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "tensor(12493)\n",
            "Train Loss: 0.0054 Acc: 0.9994\n",
            "Val Loss: 5.0651 Acc: 0.2773\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "tensor(12496)\n",
            "Train Loss: 0.0041 Acc: 0.9997\n",
            "Val Loss: 5.0462 Acc: 0.2802\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "tensor(12495)\n",
            "Train Loss: 0.0035 Acc: 0.9996\n",
            "Val Loss: 5.0292 Acc: 0.2808\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "tensor(12495)\n",
            "Train Loss: 0.0034 Acc: 0.9996\n",
            "Val Loss: 5.0208 Acc: 0.2815\n",
            "\n",
            "Training complete in 70m 13s\n",
            "Best val Acc: 0.281520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JSjsfqyiQgz",
        "outputId": "49c2d79d-146d-4454-89cf-652173a862bd"
      },
      "source": [
        "\"\"\" Training Target model \"\"\"\r\n",
        "\r\n",
        "target_train_loader = DataLoader(target_train, batch_size=64, shuffle=True, num_workers=0)\r\n",
        "target_unk_loader = DataLoader(target_unknown, batch_size=64, shuffle=True, num_workers=0)\r\n",
        "\r\n",
        "train_size = len(target_train)\r\n",
        "test_size = len(target_unknown)\r\n",
        "target_net = Target_LeNet().to(device)\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# Observe that all parameters are being optimized\r\n",
        "# target_optimizer_ft = optim.Adamax(target_net.parameters(), lr=0.001, weight_decay=1e-07)\r\n",
        "target_optimizer_ft = optim.SGD(target_net.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-07)\r\n",
        "\r\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "target_exp_lr_scheduler = lr_scheduler.StepLR(target_optimizer_ft, step_size=30, gamma=0.1)\r\n",
        "\r\n",
        "target_best_net, target_best_acc, target_last_net = train_model(target_net, target_train_loader, target_unk_loader, criterion, target_optimizer_ft, target_exp_lr_scheduler,\r\n",
        "                        num_epochs=60)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/59\n",
            "----------\n",
            "tensor(175)\n",
            "Train Loss: 4.5669 Acc: 0.0140\n",
            "Val Loss: 4.4986 Acc: 0.0162\n",
            "\n",
            "Epoch 1/59\n",
            "----------\n",
            "tensor(305)\n",
            "Train Loss: 4.4569 Acc: 0.0244\n",
            "Val Loss: 4.3973 Acc: 0.0285\n",
            "\n",
            "Epoch 2/59\n",
            "----------\n",
            "tensor(568)\n",
            "Train Loss: 4.2798 Acc: 0.0454\n",
            "Val Loss: 4.1689 Acc: 0.0686\n",
            "\n",
            "Epoch 3/59\n",
            "----------\n",
            "tensor(1029)\n",
            "Train Loss: 4.0321 Acc: 0.0823\n",
            "Val Loss: 3.9500 Acc: 0.0972\n",
            "\n",
            "Epoch 4/59\n",
            "----------\n",
            "tensor(1372)\n",
            "Train Loss: 3.8424 Acc: 0.1098\n",
            "Val Loss: 3.7954 Acc: 0.1208\n",
            "\n",
            "Epoch 5/59\n",
            "----------\n",
            "tensor(1694)\n",
            "Train Loss: 3.6709 Acc: 0.1355\n",
            "Val Loss: 3.7280 Acc: 0.1301\n",
            "\n",
            "Epoch 6/59\n",
            "----------\n",
            "tensor(1903)\n",
            "Train Loss: 3.5435 Acc: 0.1522\n",
            "Val Loss: 3.6468 Acc: 0.1521\n",
            "\n",
            "Epoch 7/59\n",
            "----------\n",
            "tensor(2176)\n",
            "Train Loss: 3.4196 Acc: 0.1741\n",
            "Val Loss: 3.5982 Acc: 0.1606\n",
            "\n",
            "Epoch 8/59\n",
            "----------\n",
            "tensor(2416)\n",
            "Train Loss: 3.3072 Acc: 0.1933\n",
            "Val Loss: 3.5899 Acc: 0.1586\n",
            "\n",
            "Epoch 9/59\n",
            "----------\n",
            "tensor(2588)\n",
            "Train Loss: 3.2327 Acc: 0.2070\n",
            "Val Loss: 3.5868 Acc: 0.1686\n",
            "\n",
            "Epoch 10/59\n",
            "----------\n",
            "tensor(2834)\n",
            "Train Loss: 3.1153 Acc: 0.2267\n",
            "Val Loss: 3.4849 Acc: 0.1836\n",
            "\n",
            "Epoch 11/59\n",
            "----------\n",
            "tensor(3121)\n",
            "Train Loss: 3.0081 Acc: 0.2497\n",
            "Val Loss: 3.4895 Acc: 0.1850\n",
            "\n",
            "Epoch 12/59\n",
            "----------\n",
            "tensor(3282)\n",
            "Train Loss: 2.9344 Acc: 0.2626\n",
            "Val Loss: 3.5414 Acc: 0.1919\n",
            "\n",
            "Epoch 13/59\n",
            "----------\n",
            "tensor(3456)\n",
            "Train Loss: 2.8226 Acc: 0.2765\n",
            "Val Loss: 3.5558 Acc: 0.1856\n",
            "\n",
            "Epoch 14/59\n",
            "----------\n",
            "tensor(3676)\n",
            "Train Loss: 2.7419 Acc: 0.2941\n",
            "Val Loss: 3.5425 Acc: 0.1983\n",
            "\n",
            "Epoch 15/59\n",
            "----------\n",
            "tensor(3864)\n",
            "Train Loss: 2.6442 Acc: 0.3091\n",
            "Val Loss: 3.6169 Acc: 0.1878\n",
            "\n",
            "Epoch 16/59\n",
            "----------\n",
            "tensor(4142)\n",
            "Train Loss: 2.5772 Acc: 0.3314\n",
            "Val Loss: 3.7347 Acc: 0.1876\n",
            "\n",
            "Epoch 17/59\n",
            "----------\n",
            "tensor(4316)\n",
            "Train Loss: 2.5036 Acc: 0.3453\n",
            "Val Loss: 3.7520 Acc: 0.1846\n",
            "\n",
            "Epoch 18/59\n",
            "----------\n",
            "tensor(4508)\n",
            "Train Loss: 2.4038 Acc: 0.3606\n",
            "Val Loss: 3.8076 Acc: 0.1785\n",
            "\n",
            "Epoch 19/59\n",
            "----------\n",
            "tensor(4842)\n",
            "Train Loss: 2.3043 Acc: 0.3874\n",
            "Val Loss: 3.8731 Acc: 0.1864\n",
            "\n",
            "Epoch 20/59\n",
            "----------\n",
            "tensor(4970)\n",
            "Train Loss: 2.2355 Acc: 0.3976\n",
            "Val Loss: 4.1162 Acc: 0.1796\n",
            "\n",
            "Epoch 21/59\n",
            "----------\n",
            "tensor(5168)\n",
            "Train Loss: 2.1766 Acc: 0.4134\n",
            "Val Loss: 4.2020 Acc: 0.1831\n",
            "\n",
            "Epoch 22/59\n",
            "----------\n",
            "tensor(5339)\n",
            "Train Loss: 2.0977 Acc: 0.4271\n",
            "Val Loss: 4.2054 Acc: 0.1814\n",
            "\n",
            "Epoch 23/59\n",
            "----------\n",
            "tensor(5466)\n",
            "Train Loss: 2.0409 Acc: 0.4373\n",
            "Val Loss: 4.3320 Acc: 0.1744\n",
            "\n",
            "Epoch 24/59\n",
            "----------\n",
            "tensor(5666)\n",
            "Train Loss: 2.0067 Acc: 0.4533\n",
            "Val Loss: 4.5009 Acc: 0.1741\n",
            "\n",
            "Epoch 25/59\n",
            "----------\n",
            "tensor(5939)\n",
            "Train Loss: 1.9016 Acc: 0.4751\n",
            "Val Loss: 4.5287 Acc: 0.1743\n",
            "\n",
            "Epoch 26/59\n",
            "----------\n",
            "tensor(6120)\n",
            "Train Loss: 1.8306 Acc: 0.4896\n",
            "Val Loss: 4.6156 Acc: 0.1655\n",
            "\n",
            "Epoch 27/59\n",
            "----------\n",
            "tensor(6214)\n",
            "Train Loss: 1.8008 Acc: 0.4971\n",
            "Val Loss: 4.7723 Acc: 0.1697\n",
            "\n",
            "Epoch 28/59\n",
            "----------\n",
            "tensor(6423)\n",
            "Train Loss: 1.7190 Acc: 0.5138\n",
            "Val Loss: 4.9800 Acc: 0.1638\n",
            "\n",
            "Epoch 29/59\n",
            "----------\n",
            "tensor(6349)\n",
            "Train Loss: 1.7258 Acc: 0.5079\n",
            "Val Loss: 5.2032 Acc: 0.1602\n",
            "\n",
            "Epoch 30/59\n",
            "----------\n",
            "tensor(8667)\n",
            "Train Loss: 1.0558 Acc: 0.6934\n",
            "Val Loss: 5.4528 Acc: 0.1841\n",
            "\n",
            "Epoch 31/59\n",
            "----------\n",
            "tensor(9508)\n",
            "Train Loss: 0.8362 Acc: 0.7606\n",
            "Val Loss: 5.7778 Acc: 0.1868\n",
            "\n",
            "Epoch 32/59\n",
            "----------\n",
            "tensor(9870)\n",
            "Train Loss: 0.7473 Acc: 0.7896\n",
            "Val Loss: 5.9935 Acc: 0.1864\n",
            "\n",
            "Epoch 33/59\n",
            "----------\n",
            "tensor(10110)\n",
            "Train Loss: 0.6841 Acc: 0.8088\n",
            "Val Loss: 6.1739 Acc: 0.1858\n",
            "\n",
            "Epoch 34/59\n",
            "----------\n",
            "tensor(10338)\n",
            "Train Loss: 0.6324 Acc: 0.8270\n",
            "Val Loss: 6.4086 Acc: 0.1842\n",
            "\n",
            "Epoch 35/59\n",
            "----------\n",
            "tensor(10538)\n",
            "Train Loss: 0.5882 Acc: 0.8430\n",
            "Val Loss: 6.6083 Acc: 0.1845\n",
            "\n",
            "Epoch 36/59\n",
            "----------\n",
            "tensor(10706)\n",
            "Train Loss: 0.5503 Acc: 0.8565\n",
            "Val Loss: 6.7980 Acc: 0.1838\n",
            "\n",
            "Epoch 37/59\n",
            "----------\n",
            "tensor(10810)\n",
            "Train Loss: 0.5150 Acc: 0.8648\n",
            "Val Loss: 7.0290 Acc: 0.1837\n",
            "\n",
            "Epoch 38/59\n",
            "----------\n",
            "tensor(10951)\n",
            "Train Loss: 0.4822 Acc: 0.8761\n",
            "Val Loss: 7.1973 Acc: 0.1818\n",
            "\n",
            "Epoch 39/59\n",
            "----------\n",
            "tensor(11077)\n",
            "Train Loss: 0.4529 Acc: 0.8862\n",
            "Val Loss: 7.4051 Acc: 0.1820\n",
            "\n",
            "Epoch 40/59\n",
            "----------\n",
            "tensor(11182)\n",
            "Train Loss: 0.4258 Acc: 0.8946\n",
            "Val Loss: 7.6398 Acc: 0.1812\n",
            "\n",
            "Epoch 41/59\n",
            "----------\n",
            "tensor(11304)\n",
            "Train Loss: 0.4008 Acc: 0.9043\n",
            "Val Loss: 7.8017 Acc: 0.1810\n",
            "\n",
            "Epoch 42/59\n",
            "----------\n",
            "tensor(11397)\n",
            "Train Loss: 0.3762 Acc: 0.9118\n",
            "Val Loss: 8.0144 Acc: 0.1820\n",
            "\n",
            "Epoch 43/59\n",
            "----------\n",
            "tensor(11488)\n",
            "Train Loss: 0.3529 Acc: 0.9190\n",
            "Val Loss: 8.1461 Acc: 0.1806\n",
            "\n",
            "Epoch 44/59\n",
            "----------\n",
            "tensor(11570)\n",
            "Train Loss: 0.3314 Acc: 0.9256\n",
            "Val Loss: 8.3927 Acc: 0.1786\n",
            "\n",
            "Epoch 45/59\n",
            "----------\n",
            "tensor(11630)\n",
            "Train Loss: 0.3120 Acc: 0.9304\n",
            "Val Loss: 8.5714 Acc: 0.1792\n",
            "\n",
            "Epoch 46/59\n",
            "----------\n",
            "tensor(11697)\n",
            "Train Loss: 0.2919 Acc: 0.9358\n",
            "Val Loss: 8.8427 Acc: 0.1786\n",
            "\n",
            "Epoch 47/59\n",
            "----------\n",
            "tensor(11769)\n",
            "Train Loss: 0.2744 Acc: 0.9415\n",
            "Val Loss: 8.9711 Acc: 0.1771\n",
            "\n",
            "Epoch 48/59\n",
            "----------\n",
            "tensor(11840)\n",
            "Train Loss: 0.2559 Acc: 0.9472\n",
            "Val Loss: 9.1774 Acc: 0.1780\n",
            "\n",
            "Epoch 49/59\n",
            "----------\n",
            "tensor(11920)\n",
            "Train Loss: 0.2402 Acc: 0.9536\n",
            "Val Loss: 9.4172 Acc: 0.1782\n",
            "\n",
            "Epoch 50/59\n",
            "----------\n",
            "tensor(11959)\n",
            "Train Loss: 0.2249 Acc: 0.9567\n",
            "Val Loss: 9.6252 Acc: 0.1784\n",
            "\n",
            "Epoch 51/59\n",
            "----------\n",
            "tensor(12023)\n",
            "Train Loss: 0.2110 Acc: 0.9618\n",
            "Val Loss: 9.8259 Acc: 0.1765\n",
            "\n",
            "Epoch 52/59\n",
            "----------\n",
            "tensor(12061)\n",
            "Train Loss: 0.1963 Acc: 0.9649\n",
            "Val Loss: 10.0105 Acc: 0.1755\n",
            "\n",
            "Epoch 53/59\n",
            "----------\n",
            "tensor(12097)\n",
            "Train Loss: 0.1848 Acc: 0.9678\n",
            "Val Loss: 10.1954 Acc: 0.1770\n",
            "\n",
            "Epoch 54/59\n",
            "----------\n",
            "tensor(12141)\n",
            "Train Loss: 0.1712 Acc: 0.9713\n",
            "Val Loss: 10.4335 Acc: 0.1766\n",
            "\n",
            "Epoch 55/59\n",
            "----------\n",
            "tensor(12169)\n",
            "Train Loss: 0.1606 Acc: 0.9735\n",
            "Val Loss: 10.5977 Acc: 0.1768\n",
            "\n",
            "Epoch 56/59\n",
            "----------\n",
            "tensor(12210)\n",
            "Train Loss: 0.1499 Acc: 0.9768\n",
            "Val Loss: 10.8247 Acc: 0.1754\n",
            "\n",
            "Epoch 57/59\n",
            "----------\n",
            "tensor(12234)\n",
            "Train Loss: 0.1410 Acc: 0.9787\n",
            "Val Loss: 11.0120 Acc: 0.1754\n",
            "\n",
            "Epoch 58/59\n",
            "----------\n",
            "tensor(12273)\n",
            "Train Loss: 0.1302 Acc: 0.9818\n",
            "Val Loss: 11.1301 Acc: 0.1738\n",
            "\n",
            "Epoch 59/59\n",
            "----------\n",
            "tensor(12288)\n",
            "Train Loss: 0.1225 Acc: 0.9830\n",
            "Val Loss: 11.3953 Acc: 0.1740\n",
            "\n",
            "Training complete in 11m 4s\n",
            "Best val Acc: 0.198320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29zVFaUi3J3V",
        "outputId": "e01df1fb-9df0-48d7-ac73-10f4c93bb2af"
      },
      "source": [
        "\"\"\" Generating Dataset (Train Set) for Attack Model using Shadow Model\"\"\"\r\n",
        "\r\n",
        "print(\"Shadow model Test set predictions: \")\r\n",
        "train_size = len(shadow_train)\r\n",
        "test_size = len(shadow_test)\r\n",
        "print(train_size, test_size)\r\n",
        "\r\n",
        "s_net = Shadow_LeNet().to(device)\r\n",
        "s_net.load_state_dict(last_net)\r\n",
        "\r\n",
        "shadow_test_prediction = test(s_net, shadow_test_loader, criterion)\r\n",
        "print(\"Shadow model Train set predictions: \")\r\n",
        "shadow_train_prediction = test(s_net, shadow_train_loader, criterion)\r\n",
        "\r\n",
        "d1 = torch.utils.data.TensorDataset(shadow_train_prediction, torch.ones(train_size, dtype=torch.long))\r\n",
        "\r\n",
        "d2 = torch.utils.data.TensorDataset(shadow_test_prediction, torch.zeros(test_size, dtype=torch.long))\r\n",
        "\r\n",
        "shadow_trained_dataset = torch.utils.data.ConcatDataset([d1, d2])\r\n",
        "\r\n",
        "len(shadow_trained_dataset)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shadow model Test set predictions: \n",
            "12500 12500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 5.5835 Acc: 0.2014\n",
            "Shadow model Train set predictions: \n",
            "Val Loss: 0.8464 Acc: 0.7888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvH9uK3xepK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c310a42d-54dc-413c-cb5b-182c28dca5c0"
      },
      "source": [
        "\"\"\" Generating Dataset (Base Train Set) for Attack Model using Base Shadow Model\"\"\"\r\n",
        "\r\n",
        "train_size = len(shadow_train)\r\n",
        "test_size = len(shadow_test)\r\n",
        "print(train_size, test_size)\r\n",
        "\r\n",
        "bs_net = Base_Shadow_LeNet().to(device)\r\n",
        "bs_net.load_state_dict(last_base_net)\r\n",
        "print(\"Shadow model Test set predictions: \")\r\n",
        "base_shadow_test_prediction = test(bs_net, shadow_test_loader, criterion)\r\n",
        "print(\"Shadow model Train set predictions: \")\r\n",
        "base_shadow_train_prediction = test(bs_net, shadow_train_loader, criterion)\r\n",
        "\r\n",
        "d1_base = torch.utils.data.TensorDataset(base_shadow_train_prediction, torch.ones(train_size, dtype=torch.long))\r\n",
        "\r\n",
        "d2_base = torch.utils.data.TensorDataset(base_shadow_test_prediction, torch.zeros(test_size, dtype=torch.long))\r\n",
        "\r\n",
        "base_shadow_trained_dataset = torch.utils.data.ConcatDataset([d1_base, d2_base])\r\n",
        "\r\n",
        "len(base_shadow_trained_dataset)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500 12500\n",
            "Shadow model Test set predictions: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 6.3963 Acc: 0.1838\n",
            "Shadow model Train set predictions: \n",
            "Val Loss: 0.6745 Acc: 0.8395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RUB1uVm-Fey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70b2f74-cc16-4926-e0a1-77ea1d152055"
      },
      "source": [
        "print(\"Sample Base Shadow Trainset data: \", base_shadow_trained_dataset[17223][0], \"Base Shadow Trainset label\", base_shadow_trained_dataset[17223][1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample Base Shadow Trainset data:  tensor([0.9378, 0.0272, 0.0093]) Base Shadow Trainset label tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYQigiPHAQxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f97eb8-d0bf-442e-e7b3-12ea0191d01a"
      },
      "source": [
        "\"\"\" Generating Dataset (ResNet Train Set) for Attack Model using ResNet Shadow\"\"\"\r\n",
        "\r\n",
        "train_size = len(shadow_train)\r\n",
        "test_size = len(shadow_test)\r\n",
        "print(train_size, test_size)\r\n",
        "resnet_net = Resnet_Shadow.to(device)\r\n",
        "resnet_net.load_state_dict(resnet_last_net)\r\n",
        "print(\"Shadow model Test set predictions: \")\r\n",
        "resnet_shadow_test_prediction = test(resnet_net, shadow_test_loader, criterion)\r\n",
        "print(\"Shadow model Train set predictions: \")\r\n",
        "resnet_shadow_train_prediction = test(resnet_net, shadow_train_loader, criterion)\r\n",
        "\r\n",
        "d1_resnet = torch.utils.data.TensorDataset(resnet_shadow_train_prediction, torch.ones(train_size, dtype=torch.long))\r\n",
        "\r\n",
        "d2_resnet = torch.utils.data.TensorDataset(resnet_shadow_test_prediction, torch.zeros(test_size, dtype=torch.long))\r\n",
        "\r\n",
        "resnet_shadow_trained_dataset = torch.utils.data.ConcatDataset([d1_resnet, d2_resnet])\r\n",
        "\r\n",
        "len(resnet_shadow_trained_dataset)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500 12500\n",
            "Shadow model Test set predictions: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 5.0208 Acc: 0.2815\n",
            "Shadow model Train set predictions: \n",
            "Val Loss: 0.0011 Acc: 0.9998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLwpDh5eB6qU",
        "outputId": "9bb26fad-694e-41d6-b3a7-c6621fdb233e"
      },
      "source": [
        "\"\"\" Generating Dataset (Validation Set) for Attack Model using Target Model\"\"\"\r\n",
        "\r\n",
        "train_size = len(target_train)\r\n",
        "test_size = len(target_unknown)\r\n",
        "\r\n",
        "t_net = Target_LeNet().to(device)\r\n",
        "t_net.load_state_dict(target_last_net)\r\n",
        "\r\n",
        "target_test_prediction = test(t_net, target_unk_loader, criterion)\r\n",
        "target_train_prediction = test(t_net, target_train_loader, criterion)\r\n",
        "\r\n",
        "d1 = torch.utils.data.TensorDataset(target_train_prediction, torch.ones(train_size, dtype=torch.long))\r\n",
        "d2 = torch.utils.data.TensorDataset(target_test_prediction, torch.zeros(test_size, dtype=torch.long))\r\n",
        "\r\n",
        "target_trained_dataset = torch.utils.data.ConcatDataset([d1, d2])\r\n",
        "len(target_trained_dataset)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 11.3953 Acc: 0.1740\n",
            "Val Loss: 0.1043 Acc: 0.9875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhWr7JG-Bgn3"
      },
      "source": [
        "train_size = len(shadow_trained_dataset)\r\n",
        "base_train_size = len(base_shadow_trained_dataset)\r\n",
        "resnet_train_size = len(resnet_shadow_trained_dataset)\r\n",
        "\r\n",
        "test_size = len(target_trained_dataset)\r\n",
        "attack_model = AttackModel(3, 64).to(device)\r\n",
        "\r\n",
        "atk_train_loader = DataLoader(shadow_trained_dataset, batch_size=10, shuffle=True, num_workers=0)\r\n",
        "atk_base_train_loader = DataLoader(base_shadow_trained_dataset, batch_size=10, shuffle=True, num_workers=0)\r\n",
        "atk_resnet_train_loader = DataLoader(resnet_shadow_trained_dataset, batch_size=10, shuffle=True, num_workers=0)\r\n",
        "\r\n",
        "\r\n",
        "atk_test_loader = DataLoader(target_trained_dataset, batch_size=10, shuffle=True, num_workers=0)\r\n",
        "optimizer_ft = optim.Adam(attack_model.parameters(), lr=0.01, weight_decay=1e-6)\r\n",
        "base_optimizer_ft = optim.Adam(attack_model.parameters(), lr=0.01, weight_decay=1e-6)\r\n",
        "resnet_optimizer_ft = optim.Adam(attack_model.parameters(), lr=0.01, weight_decay=1e-6)\r\n",
        "\r\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B6HJvaklz7H",
        "outputId": "15d436a7-60f3-4cd2-cac4-48a8237f00d4"
      },
      "source": [
        "attack_best_net, attack_best_acc, attack_last_net = train_model(attack_model, atk_train_loader, atk_test_loader, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=40, attack=True)\r\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/39\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(14186)\n",
            "Train Loss: 0.6827 Acc: 0.5674\n",
            "Val Loss: 0.6450 Acc: 0.6589\n",
            "\n",
            "Epoch 1/39\n",
            "----------\n",
            "tensor(14240)\n",
            "Train Loss: 0.6822 Acc: 0.5696\n",
            "Val Loss: 0.6558 Acc: 0.6318\n",
            "\n",
            "Epoch 2/39\n",
            "----------\n",
            "tensor(14362)\n",
            "Train Loss: 0.6809 Acc: 0.5745\n",
            "Val Loss: 0.6519 Acc: 0.6508\n",
            "\n",
            "Epoch 3/39\n",
            "----------\n",
            "tensor(14297)\n",
            "Train Loss: 0.6804 Acc: 0.5719\n",
            "Val Loss: 0.6307 Acc: 0.6832\n",
            "\n",
            "Epoch 4/39\n",
            "----------\n",
            "tensor(14242)\n",
            "Train Loss: 0.6811 Acc: 0.5697\n",
            "Val Loss: 0.6354 Acc: 0.6827\n",
            "\n",
            "Epoch 5/39\n",
            "----------\n",
            "tensor(14175)\n",
            "Train Loss: 0.6807 Acc: 0.5670\n",
            "Val Loss: 0.6519 Acc: 0.6358\n",
            "\n",
            "Epoch 6/39\n",
            "----------\n",
            "tensor(14272)\n",
            "Train Loss: 0.6810 Acc: 0.5709\n",
            "Val Loss: 0.7035 Acc: 0.5000\n",
            "\n",
            "Epoch 7/39\n",
            "----------\n",
            "tensor(14261)\n",
            "Train Loss: 0.6807 Acc: 0.5704\n",
            "Val Loss: 0.6546 Acc: 0.6327\n",
            "\n",
            "Epoch 8/39\n",
            "----------\n",
            "tensor(14293)\n",
            "Train Loss: 0.6808 Acc: 0.5717\n",
            "Val Loss: 0.6417 Acc: 0.6616\n",
            "\n",
            "Epoch 9/39\n",
            "----------\n",
            "tensor(14282)\n",
            "Train Loss: 0.6808 Acc: 0.5713\n",
            "Val Loss: 0.6490 Acc: 0.6501\n",
            "\n",
            "Epoch 10/39\n",
            "----------\n",
            "tensor(14253)\n",
            "Train Loss: 0.6807 Acc: 0.5701\n",
            "Val Loss: 0.6365 Acc: 0.6734\n",
            "\n",
            "Epoch 11/39\n",
            "----------\n",
            "tensor(14240)\n",
            "Train Loss: 0.6809 Acc: 0.5696\n",
            "Val Loss: 0.6515 Acc: 0.6387\n",
            "\n",
            "Epoch 12/39\n",
            "----------\n",
            "tensor(14241)\n",
            "Train Loss: 0.6812 Acc: 0.5696\n",
            "Val Loss: 0.6355 Acc: 0.6748\n",
            "\n",
            "Epoch 13/39\n",
            "----------\n",
            "tensor(14295)\n",
            "Train Loss: 0.6808 Acc: 0.5718\n",
            "Val Loss: 0.6551 Acc: 0.6314\n",
            "\n",
            "Epoch 14/39\n",
            "----------\n",
            "tensor(14282)\n",
            "Train Loss: 0.6803 Acc: 0.5713\n",
            "Val Loss: 0.6446 Acc: 0.6505\n",
            "\n",
            "Epoch 15/39\n",
            "----------\n",
            "tensor(14287)\n",
            "Train Loss: 0.6804 Acc: 0.5715\n",
            "Val Loss: 0.6388 Acc: 0.6616\n",
            "\n",
            "Epoch 16/39\n",
            "----------\n",
            "tensor(14339)\n",
            "Train Loss: 0.6799 Acc: 0.5736\n",
            "Val Loss: 0.6459 Acc: 0.6524\n",
            "\n",
            "Epoch 17/39\n",
            "----------\n",
            "tensor(14300)\n",
            "Train Loss: 0.6807 Acc: 0.5720\n",
            "Val Loss: 0.6489 Acc: 0.6647\n",
            "\n",
            "Epoch 18/39\n",
            "----------\n",
            "tensor(14268)\n",
            "Train Loss: 0.6805 Acc: 0.5707\n",
            "Val Loss: 0.6370 Acc: 0.6620\n",
            "\n",
            "Epoch 19/39\n",
            "----------\n",
            "tensor(14326)\n",
            "Train Loss: 0.6803 Acc: 0.5730\n",
            "Val Loss: 0.6360 Acc: 0.6784\n",
            "\n",
            "Epoch 20/39\n",
            "----------\n",
            "tensor(14233)\n",
            "Train Loss: 0.6807 Acc: 0.5693\n",
            "Val Loss: 0.6419 Acc: 0.6589\n",
            "\n",
            "Epoch 21/39\n",
            "----------\n",
            "tensor(14353)\n",
            "Train Loss: 0.6799 Acc: 0.5741\n",
            "Val Loss: 0.6479 Acc: 0.6684\n",
            "\n",
            "Epoch 22/39\n",
            "----------\n",
            "tensor(14288)\n",
            "Train Loss: 0.6807 Acc: 0.5715\n",
            "Val Loss: 0.6337 Acc: 0.6719\n",
            "\n",
            "Epoch 23/39\n",
            "----------\n",
            "tensor(14237)\n",
            "Train Loss: 0.6805 Acc: 0.5695\n",
            "Val Loss: 0.6467 Acc: 0.6442\n",
            "\n",
            "Epoch 24/39\n",
            "----------\n",
            "tensor(14309)\n",
            "Train Loss: 0.6802 Acc: 0.5724\n",
            "Val Loss: 0.6347 Acc: 0.6653\n",
            "\n",
            "Epoch 25/39\n",
            "----------\n",
            "tensor(14289)\n",
            "Train Loss: 0.6810 Acc: 0.5716\n",
            "Val Loss: 0.6372 Acc: 0.6608\n",
            "\n",
            "Epoch 26/39\n",
            "----------\n",
            "tensor(14279)\n",
            "Train Loss: 0.6802 Acc: 0.5712\n",
            "Val Loss: 0.6458 Acc: 0.6602\n",
            "\n",
            "Epoch 27/39\n",
            "----------\n",
            "tensor(14342)\n",
            "Train Loss: 0.6803 Acc: 0.5737\n",
            "Val Loss: 0.6427 Acc: 0.6638\n",
            "\n",
            "Epoch 28/39\n",
            "----------\n",
            "tensor(14315)\n",
            "Train Loss: 0.6802 Acc: 0.5726\n",
            "Val Loss: 0.6428 Acc: 0.6647\n",
            "\n",
            "Epoch 29/39\n",
            "----------\n",
            "tensor(14258)\n",
            "Train Loss: 0.6805 Acc: 0.5703\n",
            "Val Loss: 0.6526 Acc: 0.6377\n",
            "\n",
            "Epoch 30/39\n",
            "----------\n",
            "tensor(14276)\n",
            "Train Loss: 0.6804 Acc: 0.5710\n",
            "Val Loss: 0.6541 Acc: 0.6332\n",
            "\n",
            "Epoch 31/39\n",
            "----------\n",
            "tensor(14262)\n",
            "Train Loss: 0.6799 Acc: 0.5705\n",
            "Val Loss: 0.6400 Acc: 0.6647\n",
            "\n",
            "Epoch 32/39\n",
            "----------\n",
            "tensor(14287)\n",
            "Train Loss: 0.6804 Acc: 0.5715\n",
            "Val Loss: 0.6460 Acc: 0.6633\n",
            "\n",
            "Epoch 33/39\n",
            "----------\n",
            "tensor(14227)\n",
            "Train Loss: 0.6808 Acc: 0.5691\n",
            "Val Loss: 0.6401 Acc: 0.6610\n",
            "\n",
            "Epoch 34/39\n",
            "----------\n",
            "tensor(14167)\n",
            "Train Loss: 0.6804 Acc: 0.5667\n",
            "Val Loss: 0.6495 Acc: 0.6546\n",
            "\n",
            "Epoch 35/39\n",
            "----------\n",
            "tensor(14273)\n",
            "Train Loss: 0.6803 Acc: 0.5709\n",
            "Val Loss: 0.6477 Acc: 0.6543\n",
            "\n",
            "Epoch 36/39\n",
            "----------\n",
            "tensor(14243)\n",
            "Train Loss: 0.6810 Acc: 0.5697\n",
            "Val Loss: 0.6455 Acc: 0.6514\n",
            "\n",
            "Epoch 37/39\n",
            "----------\n",
            "tensor(14268)\n",
            "Train Loss: 0.6808 Acc: 0.5707\n",
            "Val Loss: 0.6391 Acc: 0.6664\n",
            "\n",
            "Epoch 38/39\n",
            "----------\n",
            "tensor(14272)\n",
            "Train Loss: 0.6806 Acc: 0.5709\n",
            "Val Loss: 0.6365 Acc: 0.6854\n",
            "\n",
            "Epoch 39/39\n",
            "----------\n",
            "tensor(14299)\n",
            "Train Loss: 0.6799 Acc: 0.5720\n",
            "Val Loss: 0.6589 Acc: 0.6263\n",
            "\n",
            "Training complete in 2m 35s\n",
            "Best val Acc: 0.685360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI6wUUBK-Icq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834b4f34-16b3-43a6-f499-c8a307de6e7a"
      },
      "source": [
        "t_l, t_p = attack_test(attack_best_net, atk_test_loader, criterion)\r\n",
        "l_true = []\r\n",
        "l_pred = []\r\n",
        "for d in t_l:\r\n",
        "    l_list = d.cpu().numpy()\r\n",
        "    for l in l_list:\r\n",
        "        l_true.append(l)\r\n",
        "# print(l_true)\r\n",
        "for d in t_p:\r\n",
        "    l_list = d.cpu().numpy()\r\n",
        "    for l in l_list:\r\n",
        "        l_pred.append(l)\r\n",
        "# print(l_pred)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 0.6365 Acc: 0.6854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHWtPsdyl1wf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac44471-b933-4cad-a762-f30d75e05197"
      },
      "source": [
        "attack_base_best_net, attack_base_best_acc, attack_base_last_net = train_model(attack_model, atk_base_train_loader, atk_test_loader, criterion, base_optimizer_ft, base_exp_lr_scheduler, num_epochs=40, attack=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/39\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(14637)\n",
            "Train Loss: 0.6748 Acc: 0.5855\n",
            "Val Loss: 0.6388 Acc: 0.6657\n",
            "\n",
            "Epoch 1/39\n",
            "----------\n",
            "tensor(14645)\n",
            "Train Loss: 0.6746 Acc: 0.5858\n",
            "Val Loss: 0.6567 Acc: 0.6265\n",
            "\n",
            "Epoch 2/39\n",
            "----------\n",
            "tensor(14636)\n",
            "Train Loss: 0.6744 Acc: 0.5854\n",
            "Val Loss: 0.6383 Acc: 0.6735\n",
            "\n",
            "Epoch 3/39\n",
            "----------\n",
            "tensor(14641)\n",
            "Train Loss: 0.6745 Acc: 0.5856\n",
            "Val Loss: 0.6233 Acc: 0.6828\n",
            "\n",
            "Epoch 4/39\n",
            "----------\n",
            "tensor(14606)\n",
            "Train Loss: 0.6743 Acc: 0.5842\n",
            "Val Loss: 0.6338 Acc: 0.6716\n",
            "\n",
            "Epoch 5/39\n",
            "----------\n",
            "tensor(14628)\n",
            "Train Loss: 0.6741 Acc: 0.5851\n",
            "Val Loss: 0.6246 Acc: 0.6734\n",
            "\n",
            "Epoch 6/39\n",
            "----------\n",
            "tensor(14698)\n",
            "Train Loss: 0.6741 Acc: 0.5879\n",
            "Val Loss: 0.6398 Acc: 0.6548\n",
            "\n",
            "Epoch 7/39\n",
            "----------\n",
            "tensor(14627)\n",
            "Train Loss: 0.6748 Acc: 0.5851\n",
            "Val Loss: 0.6348 Acc: 0.6713\n",
            "\n",
            "Epoch 8/39\n",
            "----------\n",
            "tensor(14638)\n",
            "Train Loss: 0.6746 Acc: 0.5855\n",
            "Val Loss: 0.6264 Acc: 0.6766\n",
            "\n",
            "Epoch 9/39\n",
            "----------\n",
            "tensor(14574)\n",
            "Train Loss: 0.6745 Acc: 0.5830\n",
            "Val Loss: 0.6274 Acc: 0.6812\n",
            "\n",
            "Epoch 10/39\n",
            "----------\n",
            "tensor(14671)\n",
            "Train Loss: 0.6747 Acc: 0.5868\n",
            "Val Loss: 0.6273 Acc: 0.6811\n",
            "\n",
            "Epoch 11/39\n",
            "----------\n",
            "tensor(14630)\n",
            "Train Loss: 0.6744 Acc: 0.5852\n",
            "Val Loss: 0.6331 Acc: 0.6901\n",
            "\n",
            "Epoch 12/39\n",
            "----------\n",
            "tensor(14619)\n",
            "Train Loss: 0.6752 Acc: 0.5848\n",
            "Val Loss: 0.6351 Acc: 0.6777\n",
            "\n",
            "Epoch 13/39\n",
            "----------\n",
            "tensor(14598)\n",
            "Train Loss: 0.6744 Acc: 0.5839\n",
            "Val Loss: 0.6480 Acc: 0.6522\n",
            "\n",
            "Epoch 14/39\n",
            "----------\n",
            "tensor(14680)\n",
            "Train Loss: 0.6756 Acc: 0.5872\n",
            "Val Loss: 0.6372 Acc: 0.6623\n",
            "\n",
            "Epoch 15/39\n",
            "----------\n",
            "tensor(14620)\n",
            "Train Loss: 0.6751 Acc: 0.5848\n",
            "Val Loss: 0.6260 Acc: 0.6788\n",
            "\n",
            "Epoch 16/39\n",
            "----------\n",
            "tensor(14638)\n",
            "Train Loss: 0.6743 Acc: 0.5855\n",
            "Val Loss: 0.6390 Acc: 0.6732\n",
            "\n",
            "Epoch 17/39\n",
            "----------\n",
            "tensor(14674)\n",
            "Train Loss: 0.6746 Acc: 0.5870\n",
            "Val Loss: 0.6637 Acc: 0.6165\n",
            "\n",
            "Epoch 18/39\n",
            "----------\n",
            "tensor(14629)\n",
            "Train Loss: 0.6742 Acc: 0.5852\n",
            "Val Loss: 0.6439 Acc: 0.6480\n",
            "\n",
            "Epoch 19/39\n",
            "----------\n",
            "tensor(14673)\n",
            "Train Loss: 0.6744 Acc: 0.5869\n",
            "Val Loss: 0.6324 Acc: 0.6718\n",
            "\n",
            "Epoch 20/39\n",
            "----------\n",
            "tensor(14627)\n",
            "Train Loss: 0.6743 Acc: 0.5851\n",
            "Val Loss: 0.6313 Acc: 0.6702\n",
            "\n",
            "Epoch 21/39\n",
            "----------\n",
            "tensor(14604)\n",
            "Train Loss: 0.6750 Acc: 0.5842\n",
            "Val Loss: 0.6563 Acc: 0.6271\n",
            "\n",
            "Epoch 22/39\n",
            "----------\n",
            "tensor(14629)\n",
            "Train Loss: 0.6740 Acc: 0.5852\n",
            "Val Loss: 0.6293 Acc: 0.6733\n",
            "\n",
            "Epoch 23/39\n",
            "----------\n",
            "tensor(14704)\n",
            "Train Loss: 0.6740 Acc: 0.5882\n",
            "Val Loss: 0.6285 Acc: 0.6804\n",
            "\n",
            "Epoch 24/39\n",
            "----------\n",
            "tensor(14637)\n",
            "Train Loss: 0.6745 Acc: 0.5855\n",
            "Val Loss: 0.6320 Acc: 0.6869\n",
            "\n",
            "Epoch 25/39\n",
            "----------\n",
            "tensor(14622)\n",
            "Train Loss: 0.6749 Acc: 0.5849\n",
            "Val Loss: 0.6291 Acc: 0.6744\n",
            "\n",
            "Epoch 26/39\n",
            "----------\n",
            "tensor(14586)\n",
            "Train Loss: 0.6749 Acc: 0.5834\n",
            "Val Loss: 0.6508 Acc: 0.6377\n",
            "\n",
            "Epoch 27/39\n",
            "----------\n",
            "tensor(14668)\n",
            "Train Loss: 0.6745 Acc: 0.5867\n",
            "Val Loss: 0.6603 Acc: 0.6252\n",
            "\n",
            "Epoch 28/39\n",
            "----------\n",
            "tensor(14653)\n",
            "Train Loss: 0.6744 Acc: 0.5861\n",
            "Val Loss: 0.6257 Acc: 0.6898\n",
            "\n",
            "Epoch 29/39\n",
            "----------\n",
            "tensor(14687)\n",
            "Train Loss: 0.6744 Acc: 0.5875\n",
            "Val Loss: 0.6312 Acc: 0.6674\n",
            "\n",
            "Epoch 30/39\n",
            "----------\n",
            "tensor(14650)\n",
            "Train Loss: 0.6739 Acc: 0.5860\n",
            "Val Loss: 0.6355 Acc: 0.6688\n",
            "\n",
            "Epoch 31/39\n",
            "----------\n",
            "tensor(14595)\n",
            "Train Loss: 0.6746 Acc: 0.5838\n",
            "Val Loss: 0.6358 Acc: 0.6752\n",
            "\n",
            "Epoch 32/39\n",
            "----------\n",
            "tensor(14649)\n",
            "Train Loss: 0.6741 Acc: 0.5860\n",
            "Val Loss: 0.6319 Acc: 0.6819\n",
            "\n",
            "Epoch 33/39\n",
            "----------\n",
            "tensor(14648)\n",
            "Train Loss: 0.6746 Acc: 0.5859\n",
            "Val Loss: 0.6440 Acc: 0.6478\n",
            "\n",
            "Epoch 34/39\n",
            "----------\n",
            "tensor(14607)\n",
            "Train Loss: 0.6748 Acc: 0.5843\n",
            "Val Loss: 0.6386 Acc: 0.6867\n",
            "\n",
            "Epoch 35/39\n",
            "----------\n",
            "tensor(14610)\n",
            "Train Loss: 0.6746 Acc: 0.5844\n",
            "Val Loss: 0.6346 Acc: 0.6660\n",
            "\n",
            "Epoch 36/39\n",
            "----------\n",
            "tensor(14587)\n",
            "Train Loss: 0.6743 Acc: 0.5835\n",
            "Val Loss: 0.6429 Acc: 0.6490\n",
            "\n",
            "Epoch 37/39\n",
            "----------\n",
            "tensor(14618)\n",
            "Train Loss: 0.6744 Acc: 0.5847\n",
            "Val Loss: 0.6421 Acc: 0.6537\n",
            "\n",
            "Epoch 38/39\n",
            "----------\n",
            "tensor(14613)\n",
            "Train Loss: 0.6746 Acc: 0.5845\n",
            "Val Loss: 0.6323 Acc: 0.6684\n",
            "\n",
            "Epoch 39/39\n",
            "----------\n",
            "tensor(14617)\n",
            "Train Loss: 0.6747 Acc: 0.5847\n",
            "Val Loss: 0.6380 Acc: 0.6572\n",
            "\n",
            "Training complete in 2m 38s\n",
            "Best val Acc: 0.690080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNQ4DtKYl8qQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e0738a-e403-4f8a-e921-0dae9180480a"
      },
      "source": [
        "t_base_l, t_base_p = attack_test(attack_base_best_net, atk_test_loader, criterion)\r\n",
        "l_base_true = []\r\n",
        "l_base_pred = []\r\n",
        "for d_base in t_base_l:\r\n",
        "    l_base_list = d_base.cpu().numpy()\r\n",
        "    for l_base in l_base_list:\r\n",
        "        l_base_true.append(l_base)\r\n",
        "\r\n",
        "for d_base in t_base_p:\r\n",
        "    l_base_list = d_base.cpu().numpy()\r\n",
        "    for l_base in l_base_list:\r\n",
        "        l_base_pred.append(l_base)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 0.6331 Acc: 0.6901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLlKoKUxkbgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c99344-1031-488a-f103-2e535e0544d8"
      },
      "source": [
        "attack_resnet_best_net, attack_resnet_best_acc, attack_resnet_last_net = train_model(attack_model, atk_resnet_train_loader, atk_test_loader, criterion, resnet_optimizer_ft, resnet_exp_lr_scheduler, num_epochs=40, attack=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/39\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(22755)\n",
            "Train Loss: 0.4048 Acc: 0.9102\n",
            "Val Loss: 0.7318 Acc: 0.5780\n",
            "\n",
            "Epoch 1/39\n",
            "----------\n",
            "tensor(22971)\n",
            "Train Loss: 0.3934 Acc: 0.9188\n",
            "Val Loss: 0.7432 Acc: 0.5658\n",
            "\n",
            "Epoch 2/39\n",
            "----------\n",
            "tensor(23024)\n",
            "Train Loss: 0.3918 Acc: 0.9210\n",
            "Val Loss: 0.7411 Acc: 0.5694\n",
            "\n",
            "Epoch 3/39\n",
            "----------\n",
            "tensor(23059)\n",
            "Train Loss: 0.3902 Acc: 0.9224\n",
            "Val Loss: 0.7420 Acc: 0.5682\n",
            "\n",
            "Epoch 4/39\n",
            "----------\n",
            "tensor(23098)\n",
            "Train Loss: 0.3888 Acc: 0.9239\n",
            "Val Loss: 0.7437 Acc: 0.5659\n",
            "\n",
            "Epoch 5/39\n",
            "----------\n",
            "tensor(23123)\n",
            "Train Loss: 0.3878 Acc: 0.9249\n",
            "Val Loss: 0.7427 Acc: 0.5675\n",
            "\n",
            "Epoch 6/39\n",
            "----------\n",
            "tensor(23115)\n",
            "Train Loss: 0.3881 Acc: 0.9246\n",
            "Val Loss: 0.7374 Acc: 0.5738\n",
            "\n",
            "Epoch 7/39\n",
            "----------\n",
            "tensor(23157)\n",
            "Train Loss: 0.3862 Acc: 0.9263\n",
            "Val Loss: 0.7164 Acc: 0.5954\n",
            "\n",
            "Epoch 8/39\n",
            "----------\n",
            "tensor(23143)\n",
            "Train Loss: 0.3868 Acc: 0.9257\n",
            "Val Loss: 0.7278 Acc: 0.5838\n",
            "\n",
            "Epoch 9/39\n",
            "----------\n",
            "tensor(23143)\n",
            "Train Loss: 0.3866 Acc: 0.9257\n",
            "Val Loss: 0.7398 Acc: 0.5706\n",
            "\n",
            "Epoch 10/39\n",
            "----------\n",
            "tensor(23186)\n",
            "Train Loss: 0.3851 Acc: 0.9274\n",
            "Val Loss: 0.7305 Acc: 0.5805\n",
            "\n",
            "Epoch 11/39\n",
            "----------\n",
            "tensor(23164)\n",
            "Train Loss: 0.3860 Acc: 0.9266\n",
            "Val Loss: 0.7419 Acc: 0.5683\n",
            "\n",
            "Epoch 12/39\n",
            "----------\n",
            "tensor(23178)\n",
            "Train Loss: 0.3855 Acc: 0.9271\n",
            "Val Loss: 0.7291 Acc: 0.5818\n",
            "\n",
            "Epoch 13/39\n",
            "----------\n",
            "tensor(23169)\n",
            "Train Loss: 0.3859 Acc: 0.9268\n",
            "Val Loss: 0.7445 Acc: 0.5650\n",
            "\n",
            "Epoch 14/39\n",
            "----------\n",
            "tensor(23173)\n",
            "Train Loss: 0.3855 Acc: 0.9269\n",
            "Val Loss: 0.7369 Acc: 0.5739\n",
            "\n",
            "Epoch 15/39\n",
            "----------\n",
            "tensor(23208)\n",
            "Train Loss: 0.3839 Acc: 0.9283\n",
            "Val Loss: 0.7337 Acc: 0.5771\n",
            "\n",
            "Epoch 16/39\n",
            "----------\n",
            "tensor(23201)\n",
            "Train Loss: 0.3842 Acc: 0.9280\n",
            "Val Loss: 0.7357 Acc: 0.5754\n",
            "\n",
            "Epoch 17/39\n",
            "----------\n",
            "tensor(23210)\n",
            "Train Loss: 0.3841 Acc: 0.9284\n",
            "Val Loss: 0.7363 Acc: 0.5748\n",
            "\n",
            "Epoch 18/39\n",
            "----------\n",
            "tensor(23173)\n",
            "Train Loss: 0.3855 Acc: 0.9269\n",
            "Val Loss: 0.7397 Acc: 0.5707\n",
            "\n",
            "Epoch 19/39\n",
            "----------\n",
            "tensor(23220)\n",
            "Train Loss: 0.3837 Acc: 0.9288\n",
            "Val Loss: 0.7290 Acc: 0.5817\n",
            "\n",
            "Epoch 20/39\n",
            "----------\n",
            "tensor(23217)\n",
            "Train Loss: 0.3837 Acc: 0.9287\n",
            "Val Loss: 0.7358 Acc: 0.5751\n",
            "\n",
            "Epoch 21/39\n",
            "----------\n",
            "tensor(23208)\n",
            "Train Loss: 0.3840 Acc: 0.9283\n",
            "Val Loss: 0.7326 Acc: 0.5787\n",
            "\n",
            "Epoch 22/39\n",
            "----------\n",
            "tensor(23213)\n",
            "Train Loss: 0.3839 Acc: 0.9285\n",
            "Val Loss: 0.7416 Acc: 0.5681\n",
            "\n",
            "Epoch 23/39\n",
            "----------\n",
            "tensor(23206)\n",
            "Train Loss: 0.3843 Acc: 0.9282\n",
            "Val Loss: 0.7416 Acc: 0.5680\n",
            "\n",
            "Epoch 24/39\n",
            "----------\n",
            "tensor(23229)\n",
            "Train Loss: 0.3831 Acc: 0.9292\n",
            "Val Loss: 0.7406 Acc: 0.5695\n",
            "\n",
            "Epoch 25/39\n",
            "----------\n",
            "tensor(23230)\n",
            "Train Loss: 0.3832 Acc: 0.9292\n",
            "Val Loss: 0.7460 Acc: 0.5626\n",
            "\n",
            "Epoch 26/39\n",
            "----------\n",
            "tensor(23208)\n",
            "Train Loss: 0.3842 Acc: 0.9283\n",
            "Val Loss: 0.7380 Acc: 0.5722\n",
            "\n",
            "Epoch 27/39\n",
            "----------\n",
            "tensor(23227)\n",
            "Train Loss: 0.3834 Acc: 0.9291\n",
            "Val Loss: 0.7304 Acc: 0.5804\n",
            "\n",
            "Epoch 28/39\n",
            "----------\n",
            "tensor(23202)\n",
            "Train Loss: 0.3839 Acc: 0.9281\n",
            "Val Loss: 0.7376 Acc: 0.5733\n",
            "\n",
            "Epoch 29/39\n",
            "----------\n",
            "tensor(23230)\n",
            "Train Loss: 0.3834 Acc: 0.9292\n",
            "Val Loss: 0.7439 Acc: 0.5649\n",
            "\n",
            "Epoch 30/39\n",
            "----------\n",
            "tensor(23234)\n",
            "Train Loss: 0.3831 Acc: 0.9294\n",
            "Val Loss: 0.7353 Acc: 0.5753\n",
            "\n",
            "Epoch 31/39\n",
            "----------\n",
            "tensor(23241)\n",
            "Train Loss: 0.3826 Acc: 0.9296\n",
            "Val Loss: 0.7362 Acc: 0.5742\n",
            "\n",
            "Epoch 32/39\n",
            "----------\n",
            "tensor(23247)\n",
            "Train Loss: 0.3825 Acc: 0.9299\n",
            "Val Loss: 0.7389 Acc: 0.5713\n",
            "\n",
            "Epoch 33/39\n",
            "----------\n",
            "tensor(23217)\n",
            "Train Loss: 0.3834 Acc: 0.9287\n",
            "Val Loss: 0.7379 Acc: 0.5725\n",
            "\n",
            "Epoch 34/39\n",
            "----------\n",
            "tensor(23245)\n",
            "Train Loss: 0.3827 Acc: 0.9298\n",
            "Val Loss: 0.7369 Acc: 0.5737\n",
            "\n",
            "Epoch 35/39\n",
            "----------\n",
            "tensor(23213)\n",
            "Train Loss: 0.3836 Acc: 0.9285\n",
            "Val Loss: 0.7415 Acc: 0.5677\n",
            "\n",
            "Epoch 36/39\n",
            "----------\n",
            "tensor(23243)\n",
            "Train Loss: 0.3825 Acc: 0.9297\n",
            "Val Loss: 0.7375 Acc: 0.5726\n",
            "\n",
            "Epoch 37/39\n",
            "----------\n",
            "tensor(23257)\n",
            "Train Loss: 0.3820 Acc: 0.9303\n",
            "Val Loss: 0.7395 Acc: 0.5702\n",
            "\n",
            "Epoch 38/39\n",
            "----------\n",
            "tensor(23260)\n",
            "Train Loss: 0.3822 Acc: 0.9304\n",
            "Val Loss: 0.7336 Acc: 0.5768\n",
            "\n",
            "Epoch 39/39\n",
            "----------\n",
            "tensor(23243)\n",
            "Train Loss: 0.3823 Acc: 0.9297\n",
            "Val Loss: 0.7355 Acc: 0.5750\n",
            "\n",
            "Training complete in 2m 37s\n",
            "Best val Acc: 0.595360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtepfboTks1U",
        "outputId": "83d4b9e6-efe6-4846-bf3b-21478826f4a8"
      },
      "source": [
        "t_resnet_l, t_resnet_p = attack_test(attack_resnet_best_net, atk_test_loader, criterion)\r\n",
        "l_resnet_true = []\r\n",
        "l_resnet_pred = []\r\n",
        "for d_resnet in t_resnet_l:\r\n",
        "    l_resnet_list = d_resnet.cpu().numpy()\r\n",
        "    for l_resnet in l_resnet_list:\r\n",
        "        l_resnet_true.append(l_resnet)\r\n",
        "\r\n",
        "for d_resnet in t_resnet_p:\r\n",
        "    l_resnet_list = d_resnet.cpu().numpy()\r\n",
        "    for l_resnet in l_resnet_list:\r\n",
        "        l_resnet_pred.append(l_resnet)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val Loss: 0.7164 Acc: 0.5954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB5e2_fOgXkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3237d5b9-3c69-49af-c310-985c171fb1b6"
      },
      "source": [
        "#Check Attack Accuracy using Shadow Model\r\n",
        "\r\n",
        "zip_lists = zip(l_true, l_pred)\r\n",
        "count = 0\r\n",
        "for list_t, list_p in zip_lists:\r\n",
        "  if list_t-list_p == 0:\r\n",
        "    count += 1\r\n",
        "\r\n",
        "accuracy = (count / len(l_true)) * 100\r\n",
        "\r\n",
        "print(\"Attack Accuracy using Shadow Model: \", accuracy, \"%\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attack Accuracy using Shadow Model:  68.536 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmAZj1pbne8z",
        "outputId": "06e53bb0-f124-4827-cd60-41d477fb8075"
      },
      "source": [
        "#Check Attack Accuracy using Base Shodow Model\r\n",
        "\r\n",
        "zip_base_lists = zip(l_base_true, l_base_pred)\r\n",
        "base_count = 0\r\n",
        "for list_base_t, list_base_p in zip_base_lists:\r\n",
        "  if list_base_t-list_base_p == 0:\r\n",
        "    base_count += 1\r\n",
        "\r\n",
        "base_accuracy = (base_count / len(l_base_true)) * 100\r\n",
        "\r\n",
        "print(\"Attack Accuracy using Base Shadow Model: \", base_accuracy, \"%\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attack Accuracy using Base Shadow Model:  69.00800000000001 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVa7tfa_lRzN",
        "outputId": "0b49f807-5890-4eab-b5d4-9259491aec0e"
      },
      "source": [
        "#Check Attack Accuracy using Base ResNet Shodow\r\n",
        "\r\n",
        "zip_resnet_lists = zip(l_resnet_true, l_resnet_pred)\r\n",
        "resnet_count = 0\r\n",
        "for list_resnet_t, list_resnet_p in zip_resnet_lists:\r\n",
        "  if list_resnet_t-list_resnet_p == 0:\r\n",
        "    resnet_count += 1\r\n",
        "\r\n",
        "resnet_accuracy = (resnet_count / len(l_resnet_true)) * 100\r\n",
        "\r\n",
        "print(\"Attack Accuracy using ResNet Shadow: \", resnet_accuracy, \"%\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attack Accuracy using ResNet Shadow:  59.536 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}